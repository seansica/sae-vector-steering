{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O8tQblzOVHu"
      },
      "source": [
        "# A very basic SAE Training Tutorial\n",
        "\n",
        "Please note that it is very easy for tutorial code to go stale so please have a low bar for raising an issue in the"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shAFb9-lOVHu"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LeRi_tw2dhae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sae-lens in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (3.12.0)\n",
            "Requirement already satisfied: transformer-lens in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (2.2.1)\n",
            "Collecting circuitsvis\n",
            "  Downloading circuitsvis-1.43.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: automated-interpretability<0.0.4,>=0.0.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (0.0.3)\n",
            "Requirement already satisfied: babe<0.0.8,>=0.0.7 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (0.0.7)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.17.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (2.20.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (3.9.1)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (0.1.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (3.8.1)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.19.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (5.22.0)\n",
            "Requirement already satisfied: plotly-express<0.5.0,>=0.4.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (0.4.1)\n",
            "Requirement already satisfied: pytest-profiling<2.0.0,>=1.7.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (1.7.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (1.0.1)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (6.0.1)\n",
            "Requirement already satisfied: pyzmq==26.0.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (26.0.0)\n",
            "Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (0.4.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (4.42.4)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (4.12.2)\n",
            "Requirement already satisfied: zstandard<0.23.0,>=0.22.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sae-lens) (0.22.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.26.1)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.0.3)\n",
            "Requirement already satisfied: einops>=0.6.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.7.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.2.25)\n",
            "Requirement already satisfied: numpy>=1.24 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (2.2.0)\n",
            "Requirement already satisfied: rich>=12.6.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (13.7.0)\n",
            "Requirement already satisfied: sentencepiece in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.2.0)\n",
            "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (2.1.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (4.66.4)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformer-lens) (0.16.2)\n",
            "Requirement already satisfied: importlib-metadata>=5.1.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from circuitsvis) (7.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (23.2)\n",
            "Requirement already satisfied: psutil in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (5.9.8)\n",
            "Requirement already satisfied: huggingface-hub in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (0.23.4)\n",
            "Requirement already satisfied: blobfile<3.0.0,>=2.1.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2.1.1)\n",
            "Requirement already satisfied: boostedblob<0.16.0,>=0.15.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens) (0.15.4)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.10.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens) (3.10.6)\n",
            "Requirement already satisfied: pytest<9.0.0,>=8.1.2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens) (8.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.4.2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens) (1.4.2)\n",
            "Requirement already satisfied: tiktoken<0.7.0,>=0.6.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens) (0.6.0)\n",
            "Requirement already satisfied: py2store in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.20)\n",
            "Requirement already satisfied: graze in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.17)\n",
            "Requirement already satisfied: filelock in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets<3.0.0,>=2.17.1->sae-lens) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.9.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.17.0)\n",
            "Requirement already satisfied: typeguard<3,>=2.13.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from jaxtyping>=0.2.11->transformer-lens) (2.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.14.1)\n",
            "Requirement already satisfied: click in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (2023.12.25)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from pandas>=1.1.5->transformer-lens) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from pandas>=1.1.5->transformer-lens) (2023.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from plotly<6.0.0,>=5.19.0->sae-lens) (8.2.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.14.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (1.13.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.5.6)\n",
            "Requirement already satisfied: six in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.16.0)\n",
            "Requirement already satisfied: gprof2dot in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2024.6.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from rich>=12.6.0->transformer-lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from rich>=12.6.0->transformer-lens) (2.17.2)\n",
            "Requirement already satisfied: sympy in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (3.1.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from transformers<5.0.0,>=4.38.1->sae-lens) (0.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from typer<0.13.0,>=0.12.3->sae-lens) (1.5.4)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (3.1.41)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (1.39.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (69.0.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (4.25.2)\n",
            "Requirement already satisfied: pycryptodomex~=3.8 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (3.20.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2.1.0)\n",
            "Requirement already satisfied: lxml~=4.9 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (4.9.4)\n",
            "Requirement already satisfied: uvloop>=0.16.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (0.19.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.9.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (4.0.11)\n",
            "Requirement already satisfied: anyio in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (4.2.0)\n",
            "Requirement already satisfied: certifi in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (1.0.5)\n",
            "Requirement already satisfied: idna in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (3.6)\n",
            "Requirement already satisfied: sniffio in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens) (0.1.2)\n",
            "Requirement already satisfied: iniconfig in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.5 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae-lens) (3.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from scikit-learn<2.0.0,>=1.4.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (3.5.0)\n",
            "Requirement already satisfied: dol in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from graze->babe<0.0.8,>=0.0.7->sae-lens) (0.2.49)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (2.1.4)\n",
            "Requirement already satisfied: config2py in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.33)\n",
            "Requirement already satisfied: importlib-resources in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (6.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (5.0.1)\n",
            "Requirement already satisfied: i2 in /Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.17)\n",
            "Downloading circuitsvis-1.43.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: circuitsvis\n",
            "Successfully installed circuitsvis-1.43.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    #import google.colab # type: ignore\n",
        "    #from google.colab import output\n",
        "    %pip install sae-lens transformer-lens circuitsvis\n",
        "except:\n",
        "    from IPython import get_ipython # type: ignore\n",
        "    ipython = get_ipython(); assert ipython is not None\n",
        "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
        "    ipython.run_line_magic(\"autoreload\", \"2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy-b3CcSOVHu",
        "outputId": "58ce28d0-f91f-436d-cf87-76bb26e2ecaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe2nlqf-OVHv"
      },
      "source": [
        "# Model Selection and Evaluation (Feel Free to Skip)\n",
        "\n",
        "We'll use the runner to train an SAE on a TinyStories Model. This is a very small model so we can train an SAE on it quite quickly. Before we get started, let's load in the model with `transformer_lens` and see what it can do.\n",
        "\n",
        "TransformerLens gives us 2 functions that are useful here (and circuits viz provides a third):\n",
        "1. `transformer_lens.utils.test_prompt` will help us see when the model can infer one token.\n",
        "2. `HookedTransformer.generate` will help us see what happens when we sample from the model.\n",
        "3. `circuitsvis.logits.token_log_probs` will help us visualize the log probs of tokens at several positions in a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hFz6JUMuOVHv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e14fe8febc1f4779933a3ccbae3050f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc84108e8c344cb59e3ce357cce5d621",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/269M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/seansica/.pyenv/versions/3.11.9/envs/nlp/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63794b37651041ff959094eceb7ba1b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/722 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bca5182ef6e549bb951ea475c135df77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a96e8a743fc64f38b74d36f5537fc656",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d839b74decbc4804860e07e184a67cb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7252190d257647ed9f670a7dbc930f43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "from transformer_lens import HookedTransformer\n",
        "\n",
        "model = HookedTransformer.from_pretrained(\n",
        "    \"tiny-stories-1L-21M\"\n",
        ")  # This will wrap huggingface models and has lots of nice utilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUiXrjdUOVHv"
      },
      "source": [
        "### Getting a vibe for a model using `model.generate`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZfKT5aDOVHv"
      },
      "source": [
        "Let's start by generating some stories using the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G4ad4Zz1OVHv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Once upon a time, there was a powerful woman who was embarrassed about something she had never seen before. One day, while she was walking in the forest, a tiny creature came out of the bushes! The woman said she wanted to take the girl home. But the'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Once upon a time, there lived a funny dragon. He liked to explore and have fun. One day, the dragon and his mommy got lost in the woods. He wanted to make it close to everyone he met. So, the dragon decided to introduce himself and'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Once upon a time, the tree was in the meadow. He lived cautiously amongst the branches and often the birds in the sky. Most days he would climb up a tall tree and sit in the meadow. \\nOne day, the tall tree started to get'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Once upon a time, there was a boy named Jack. He had a helpful ride on his bicycle that was a bright light. Every day he would go for a ride in the sun and it made him so happy.\\n\\nOne day, Jack was riding his bicycle'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Once upon a time, there were two brothers. One brother was called Jack and he was very wealthy and could afford a lot of fruit. Jack decided to win the contest because he liked apples.\\n\\nWhen the competition was over, the bigger brother Tom gave John all'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# here we use generate to get 10 completeions with temperature 1. Feel free to play with the prompt to make it more interesting.\n",
        "for i in range(5):\n",
        "    display(\n",
        "        model.generate(\n",
        "            \"Once upon a time\",\n",
        "            stop_at_eos=False,  # avoids a bug on MPS\n",
        "            temperature=1,\n",
        "            verbose=False,\n",
        "            max_new_tokens=50,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDKr8o1xOVHv"
      },
      "source": [
        "One thing we notice is that the model seems to be able to repeat the name of the main character very consistently. It can output a pronoun intead but in some stories will repeat the protagonists name. This seems like an interesting capability to analyse with SAEs. To better understand the models ability to remember the protagonists name, let's extract a prompt where the next character is determined and use the \"test_prompt\" utility from TransformerLens to check the ranking of the token for that name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsfJX-YpOVHv"
      },
      "source": [
        "### Spot checking model abilities with `transformer_lens.utils.test_prompt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TpmPoj7uOVHv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized prompt: ['<|endoftext|>', 'Once', ' upon', ' a', ' time', ',', ' there', ' was', ' a', ' little', ' girl', ' named', ' Lily', '.', ' She', ' lived', ' in', ' a', ' big', ',', ' happy', ' little', ' girl', '.', ' On', ' her', ' big', ' adventure', ',']\n",
            "Tokenized answer: [' Lily']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.81</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.46</span><span style=\"font-weight: bold\">% Token: | Lily|</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.81\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m13.46\u001b[0m\u001b[1m% Token: | Lily|\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0th token. Logit: 20.48 Prob: 71.06% Token: | she|\n",
            "Top 1th token. Logit: 18.81 Prob: 13.46% Token: | Lily|\n",
            "Top 2th token. Logit: 17.35 Prob:  3.11% Token: | the|\n",
            "Top 3th token. Logit: 17.26 Prob:  2.86% Token: | her|\n",
            "Top 4th token. Logit: 16.74 Prob:  1.70% Token: | there|\n",
            "Top 5th token. Logit: 16.43 Prob:  1.25% Token: | they|\n",
            "Top 6th token. Logit: 15.80 Prob:  0.66% Token: | all|\n",
            "Top 7th token. Logit: 15.64 Prob:  0.56% Token: | things|\n",
            "Top 8th token. Logit: 15.28 Prob:  0.39% Token: | one|\n",
            "Top 9th token. Logit: 15.24 Prob:  0.38% Token: | lived|\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Lily'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Lily'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformer_lens.utils import test_prompt\n",
        "\n",
        "# Test the model with a prompt\n",
        "test_prompt(\n",
        "    \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little girl. On her big adventure,\",\n",
        "    \" Lily\",\n",
        "    model,\n",
        "    prepend_space_to_answer=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGzOvReDOVHv"
      },
      "source": [
        "In the output above, we see that the model assigns ~ 70% probability to \"she\" being the next token, and a 13% chance to \" Lily\" being the next token. Other names like Lucy or Anna are not highly ranked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH8YOZOzOVHv"
      },
      "source": [
        "### Exploring Model Capabilities with Log Probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50mqTBihOVHw"
      },
      "source": [
        "Looking at token ranking for a single prompt is interesting, but a much higher through way to understand models is to look at token log probs for all tokens in text. We can use the `circuits_vis` package to get a nice visualization where we can see tokenization, and hover to get the top5 tokens by log probability. Darker tokens are tokens where the model assigned a higher probability to the actual next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Tic0RCUpOVHw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"circuits-vis-7634c6cf-67aa\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-7634c6cf-67aa\",\n",
              "      TokenLogProbs,\n",
              "      {\"prompt\": [\"<|endoftext|>\", \"Hi\", \",\", \" how\", \" are\", \" you\", \" doing\", \" this\", \"?\", \" I\", \"'m\", \" really\", \" enjoying\", \" your\", \" posts\"], \"topKLogProbs\": [[-0.020238446071743965, -6.104495525360107, -7.070316791534424, -7.073482990264893, -7.178877353668213, -7.389682292938232, -7.525310039520264, -7.588572025299072, -7.763051509857178, -8.224309921264648], [-1.1883925199508667, -3.4683876037597656, -3.4808263778686523, -3.489603042602539, -3.500030517578125, -3.5543575286865234, -4.017884254455566, -4.030545234680176, -4.298163414001465, -4.4181718826293945], [-2.9201362133026123, -3.3794772624969482, -3.426678419113159, -3.5317533016204834, -3.956158399581909, -4.256061553955078, -4.44394588470459, -4.4448442459106445, -4.559994697570801, -4.583304405212402], [-0.9917572736740112, -2.9286718368530273, -3.2575292587280273, -3.317974090576172, -3.474062919616699, -3.6419153213500977, -3.867489814758301, -3.8686323165893555, -3.8917036056518555, -4.005288124084473], [-0.03712325915694237, -4.683361530303955, -4.9722771644592285, -5.854292392730713, -5.942135334014893, -6.3880295753479, -6.394075870513916, -6.4985833168029785, -6.593430042266846, -7.869250774383545], [-0.2348635494709015, -2.3354170322418213, -2.947492837905884, -5.052801609039307, -5.078567981719971, -5.102743625640869, -5.116295337677002, -5.73727560043335, -5.768457889556885, -5.893761157989502], [-0.4488484263420105, -2.0767171382904053, -3.433582067489624, -3.6450765132904053, -3.7033822536468506, -4.046279430389404, -4.0969977378845215, -4.209788799285889, -4.5189642906188965, -4.961881160736084], [-0.46094387769699097, -2.737765073776245, -3.1589114665985107, -3.686793088912964, -4.4164299964904785, -4.448526859283447, -4.571943759918213, -4.669151782989502, -4.69536828994751, -4.748208522796631], [-0.9866085052490234, -1.8349876403808594, -2.4600276947021484, -2.511577606201172, -3.115631103515625, -3.419487953186035, -3.5203638076782227, -3.804978370666504, -4.003084182739258, -4.258262634277344], [-1.3091981410980225, -1.63388991355896, -1.7868058681488037, -2.631612539291382, -3.4602792263031006, -3.6158502101898193, -4.020038604736328, -4.093286514282227, -4.177452087402344, -4.309240341186523], [-1.9952362775802612, -2.5565366744995117, -2.645552635192871, -2.894824981689453, -3.1104421615600586, -3.394558906555176, -3.7311220169067383, -3.8203353881835938, -3.967905044555664, -4.026362419128418], [-1.0431110858917236, -1.9594700336456299, -3.05077862739563, -3.4214890003204346, -3.480107545852661, -3.489844560623169, -3.6019928455352783, -4.332498550415039, -4.492424964904785, -4.517613410949707], [-1.5123926401138306, -2.0202813148498535, -2.223288059234619, -2.24931001663208, -3.3765206336975098, -3.9217019081115723, -3.9798378944396973, -4.199244022369385, -4.265364170074463, -4.661587238311768], [-3.188739776611328, -3.192066192626953, -3.425212860107422, -3.494190216064453, -3.7325963973999023, -3.735321044921875, -3.7357072830200195, -3.8339614868164062, -4.23370361328125, -4.2657012939453125]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\",\", \" Tim\", \" bird\", \"!\", \" little\", \" Lily\", \" Tom\", \"!\\\"\", \" Max\", \" tree\"], [\" cat\", \" a\", \" bird\", \" little\", \" I\", \"\\n\", \" dog\", \" but\", \" frog\", \" sw\"], [\" are\", \" I\", \" was\", \" do\", \" fast\", \" big\", \" did\", \" to\", \" he\", \" old\"], [\" you\", \" we\", \" they\", \" the\", \" Lily\", \" your\", \" I\", \" Tim\", \" friends\", \" those\"], [\"?\\\"\", \" today\", \"?\", \" and\", \".\", \",\", \" doing\", \" going\", \" up\", \"?\\\".\"], [\"?\\\"\", \" this\", \" today\", \"?\", \" here\", \" a\", \" it\", \" these\", \".\", \" in\"], [\"?\\\"\", \"?\", \" great\", \" so\", \" job\", \" puzzle\", \" task\", \" very\", \".\", \" amazing\"], [\"\\ufffd\", \" You\", \" I\", \" It\", \" We\", \" Can\", \"\\n\", \" This\", \" Do\", \" Are\"], [\"'m\", \" am\", \" want\", \" like\", \" know\", \" have\", \" love\", \" can\", \" just\", \" hope\"], [\" a\", \" so\", \" very\", \" trying\", \" going\", \" an\", \" looking\", \" just\", \" making\", \" playing\"], [\" good\", \" hungry\", \" enjoying\", \" a\", \" tired\", \" proud\", \" happy\", \" excited\", \" busy\", \" glad\"], [\" the\", \" it\", \" this\", \" my\", \" a\", \" your\", \" playing\", \" some\", \" these\", \" myself\"], [\" meal\", \" food\", \" day\", \" ice\", \" sandwich\", \" delicious\", \" new\", \" dance\", \" cake\", \" time\"]], \"correctTokenRank\": [1718, 0, 675, 0, 0, 6, 1, 1, 2, 0, 23, 2, 5, 10036], \"correctTokenLogProb\": [-13.81494426727295, -1.1883925199508667, -8.445568084716797, -0.9917572736740112, -0.03712325915694237, -5.116295337677002, -2.0767171382904053, -2.737765073776245, -2.4600276947021484, -1.3091981410980225, -4.860555648803711, -3.05077862739563, -3.9217019081115723, -17.039501190185547]}\n",
              "    )\n",
              "    </script>"
            ],
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x17fece9d0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
        "\n",
        "# Let's make a longer prompt and see the log probabilities of the tokens\n",
        "example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n",
        "logits, cache = model.run_with_cache(example_prompt)\n",
        "cv.logits.token_log_probs(\n",
        "    model.to_tokens(example_prompt),\n",
        "    model(example_prompt)[0].log_softmax(dim=-1),\n",
        "    model.to_string,\n",
        ")\n",
        "# hover on the output to see the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhGIl3YbOVHw"
      },
      "source": [
        "Let's combine `model.generate` and the token log probs visualization to see the log probs on text generated by the model. Note that we can play with the temperature and this should sample less likely trajectories according to the model. I've increased the maximum number of tokens in order to get a full story.\n",
        "\n",
        "Some things to explore:\n",
        "- Which tokens does the model assign high probability to? Can you see how the model should know which word comes next?\n",
        "- What happens if you increase / decrease the temperature?\n",
        "- Do the rankings of tokens seem sensible to you? What about where the model doesn't assign a high probability to the token which came next?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nikp2ASlOVHw"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bbba88c91a041aba29801c6c32d13e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div id=\"circuits-vis-fa45e97f-12e1\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-fa45e97f-12e1\",\n",
              "      TokenLogProbs,\n",
              "      {\"prompt\": [\"<|endoftext|>\", \"Once\", \" upon\", \" a\", \" time\", \",\", \" there\", \" was\", \" a\", \" '\", \"em\", \" Rocks\", \"'.\\\"\", \"\\n\", \"\\n\", \"At\", \" the\", \" end\", \" of\", \" the\", \" day\", \",\", \" everyone\", \" got\", \" out\", \" of\", \" the\", \" cave\", \" and\", \" saw\", \" a\", \" beautiful\", \" lake\", \".\", \" The\", \" bear\", \" learned\", \" so\", \" valuable\", \" that\", \" it\", \"'s\", \" better\", \" to\", \" stay\", \" safe\", \" than\", \" sorry\", \".\", \"\\n\", \"<|endoftext|>\", \" shiny\", \" like\", \" a\", \" shiny\", \" toy\", \" car\", \".\", \" The\", \" bear\", \" and\", \" Tom\", \" thanked\", \" the\", \" ot\", \"ter\", \" for\", \" being\", \" so\", \" kind\", \".\", \" He\", \" said\", \",\", \" '\", \"You\", \"'re\", \" welcome\", \" little\", \" duck\", \".\", \" Whenever\", \" you\", \"'re\", \" scared\", \" and\", \" don\", \"'t\", \" come\", \" up\", \" quickly\", \" remembers\", \" you\", \".\\\"\", \" They\", \" became\", \" the\", \" best\", \" of\", \" friends\", \" and\", \" always\", \" welcomed\", \" in\", \" the\", \" lake\", \".\", \"\\n\", \"\\n\", \"Tom\", \" and\", \" the\", \" duck\", \" had\", \" lots\", \" of\", \" fun\", \" together\", \",\", \" and\", \" they\", \" explored\", \" the\", \" cabin\", \".\", \" There\", \",\", \" they\", \" discovered\", \" a\", \" special\", \" place\", \" and\", \" all\", \" the\", \" beautiful\", \" things\", \".\", \"\\n\", \"\\n\", \"The\", \" fit\", \" friends\", \" had\", \" shown\", \" the\", \" baby\", \" around\", \" and\", \" enjoyed\", \" being\", \" together\", \" forever\", \".\", \" He\", \" never\", \" regretted\", \" it\", \" again\", \".\", \"\\n\", \"<|endoftext|>\", \" large\", \" visits\", \" all\", \" the\", \" other\", \" exciting\", \" places\", \" she\", \" could\", \" visit\", \" during\", \" the\", \" days\", \",\", \" and\", \" the\", \" beautiful\", \" forest\", \".\", \"\\n\", \"<|endoftext|>\", \" brave\", \"ly\", \" poss\", \"n\", \"icked\", \" the\", \" baby\", \"'s\", \" face\", \" and\", \" thanked\", \" the\", \" lake\", \" for\", \" the\", \" wonderful\", \" time\", \" she\", \" had\", \" seen\", \" something\", \" so\"], \"topKLogProbs\": [[-0.020238328725099564, -6.1045098304748535, -7.070322513580322, -7.073493480682373, -7.1788811683654785, -7.38969087600708, -7.52532434463501, -7.588578701019287, -7.763062000274658, -8.22431755065918], [-0.37248945236206055, -1.8275341987609863, -4.306140422821045, -4.838802814483643, -4.989409923553467, -5.111741542816162, -5.187069416046143, -5.250611782073975, -5.66286039352417, -5.694159030914307], [-0.005904612597078085, -5.495631694793701, -7.522141933441162, -8.20771312713623, -8.449639320373535, -8.907076835632324, -9.541238784790039, -9.691882133483887, -10.111759185791016, -10.492283821105957], [-0.011737924069166183, -6.031049728393555, -7.209388732910156, -7.243852615356445, -7.7479400634765625, -7.977014541625977, -8.32171630859375, -8.357282638549805, -8.502368927001953, -8.701488494873047], [-0.18781612813472748, -1.8141779899597168, -5.624234676361084, -6.5796427726745605, -7.822267055511475, -8.386680603027344, -8.49909782409668, -8.578043937683105, -8.8237943649292, -8.96056079864502], [-0.10250573605298996, -3.4027299880981445, -3.9464731216430664, -5.159356117248535, -5.411175727844238, -6.113492012023926, -6.131925582885742, -6.200304985046387, -6.424897193908691, -7.00716495513916], [-0.13827048242092133, -2.5443506240844727, -3.050601005554199, -7.775616645812988, -8.04969310760498, -8.075804710388184, -8.107096672058105, -8.183037757873535, -8.868160247802734, -8.878031730651855], [-0.03213061764836311, -3.6293787956237793, -7.6953606605529785, -7.812199115753174, -7.890786647796631, -8.088067054748535, -8.264233589172363, -9.07732105255127, -9.536678314208984, -9.68324089050293], [-1.8430554866790771, -2.412818670272827, -2.9645020961761475, -3.6159703731536865, -4.06175422668457, -4.090792655944824, -4.206700325012207, -4.358070373535156, -4.6263580322265625, -4.680698394775391], [-2.6813035011291504, -3.490622043609619, -3.7975172996520996, -3.8209404945373535, -4.107102870941162, -4.391723155975342, -4.4726881980896, -4.47986364364624, -4.583838939666748, -4.584364414215088], [-2.2663161754608154, -3.0650508403778076, -3.264633893966675, -3.3455159664154053, -3.596036672592163, -3.8083016872406006, -3.9278018474578857, -3.935663938522339, -3.962122678756714, -4.114118576049805], [-0.7409992218017578, -0.7708072662353516, -3.7856063842773438, -4.249187469482422, -4.620782852172852, -5.772218704223633, -6.012847900390625, -7.395302772521973, -7.490695953369141, -7.610651016235352], [-1.1125653982162476, -1.9612268209457397, -2.4154648780822754, -2.5692849159240723, -3.063788890838623, -3.1830382347106934, -4.2515482902526855, -4.508462429046631, -4.564062595367432, -4.7136454582214355], [-0.38108062744140625, -3.3363027572631836, -3.768486976623535, -3.7753028869628906, -3.8093318939208984, -3.8613710403442383, -4.318001747131348, -4.391056060791016, -4.7762908935546875, -4.782558441162109], [-1.9205878973007202, -1.9924529790878296, -2.688599109649658, -2.9816784858703613, -3.078613758087158, -3.288534641265869, -3.3053879737854004, -3.4519753456115723, -3.478720188140869, -3.6214375495910645], [-0.4633193612098694, -2.61598539352417, -2.6820578575134277, -3.0369887351989746, -3.1902823448181152, -3.777369976043701, -3.8599658012390137, -4.276774883270264, -4.525444507598877, -5.029919147491455], [-1.4594554901123047, -2.184859275817871, -2.3324317932128906, -2.6000661849975586, -2.934612274169922, -3.5753355026245117, -3.76828670501709, -3.803913116455078, -3.9258041381835938, -4.084512710571289], [-0.0895572230219841, -2.507230281829834, -6.6378703117370605, -8.10912799835205, -8.245896339416504, -8.376827239990234, -8.50886344909668, -8.584297180175781, -9.589126586914062, -9.67750358581543], [-0.1588805615901947, -3.7127439975738525, -3.9490911960601807, -3.961557626724243, -4.282288074493408, -4.363871097564697, -4.44488000869751, -4.73209810256958, -4.765905857086182, -5.190592288970947], [-0.731742262840271, -2.450528621673584, -3.081296443939209, -3.4110655784606934, -3.602120876312256, -3.785658359527588, -3.8310904502868652, -4.143956661224365, -4.22503137588501, -4.563720226287842], [-0.03783838450908661, -4.704979419708252, -5.524569034576416, -5.705654621124268, -5.881004810333252, -6.663562297821045, -6.6865315437316895, -6.761807918548584, -6.8050408363342285, -7.0386786460876465], [-1.04152512550354, -2.906233072280884, -2.9559366703033447, -3.5232937335968018, -3.5413076877593994, -3.5648996829986572, -4.026082992553711, -4.171464920043945, -4.214141845703125, -4.304262161254883], [-0.8313478827476501, -2.5134520530700684, -3.0385470390319824, -3.3417906761169434, -3.676490306854248, -3.7807459831237793, -3.7951464653015137, -4.0627570152282715, -4.082810878753662, -4.483361721038818], [-2.037766218185425, -2.3466289043426514, -2.370678663253784, -2.5420081615448, -2.814958333969116, -2.963495969772339, -3.0009992122650146, -3.077122449874878, -3.746040105819702, -3.805464506149292], [-0.0938071459531784, -2.923856735229492, -4.448207855224609, -4.994054794311523, -6.228374481201172, -6.429300308227539, -6.572746276855469, -6.667240142822266, -6.680442810058594, -6.700893402099609], [-0.34039992094039917, -2.07609486579895, -2.901332139968872, -2.995877504348755, -3.604825258255005, -4.9439802169799805, -5.257796287536621, -6.514472961425781, -6.519144058227539, -6.604203224182129], [-1.5050431489944458, -2.1810531616210938, -2.2017822265625, -3.2983293533325195, -3.7109336853027344, -3.9073963165283203, -3.9168386459350586, -4.106413841247559, -4.34306526184082, -4.590906143188477], [-0.8454670310020447, -0.8737682700157166, -3.0533127784729004, -3.9456868171691895, -4.304764270782471, -4.492273807525635, -4.862082004547119, -4.939259052276611, -5.517331600189209, -5.6549859046936035], [-1.671362280845642, -2.818840503692627, -3.007681369781494, -3.0611910820007324, -3.2623867988586426, -3.412071704864502, -3.466548442840576, -3.7024073600769043, -3.760399341583252, -3.839850902557373], [-0.6200908422470093, -1.6874717473983765, -2.5948052406311035, -3.05527925491333, -3.1972126960754395, -3.4683899879455566, -4.596458911895752, -4.943528652191162, -5.178517818450928, -5.218555927276611], [-1.9465820789337158, -1.9614765644073486, -3.070936441421509, -3.359318971633911, -3.4190895557403564, -3.5949928760528564, -3.7434990406036377, -4.026723861694336, -4.118874549865723, -4.236105918884277], [-2.078320026397705, -3.002699375152588, -3.245513439178467, -3.249014377593994, -3.512326717376709, -3.5952095985412598, -3.5969491004943848, -3.623413562774658, -3.6826605796813965, -3.7753453254699707], [-0.09932177513837814, -3.7715344429016113, -4.248262882232666, -5.028616428375244, -5.222628116607666, -5.296665668487549, -5.618139743804932, -5.730076313018799, -6.05340051651001, -6.139166355133057], [-1.1424922943115234, -2.073545455932617, -2.1939010620117188, -2.766813278198242, -3.0347604751586914, -3.0488719940185547, -3.6790733337402344, -3.696981430053711, -3.736578941345215, -4.080166816711426], [-1.8096685409545898, -2.6261444091796875, -2.713433265686035, -2.922146797180176, -3.1371965408325195, -3.169797897338867, -3.459597587585449, -3.4945478439331055, -3.8409547805786133, -3.9342823028564453], [-1.291812539100647, -1.8773285150527954, -2.7759127616882324, -3.104569911956787, -3.2442145347595215, -3.2603297233581543, -3.846047878265381, -3.8955531120300293, -3.982978343963623, -4.020986080169678], [-0.8688695430755615, -1.809579610824585, -2.099139928817749, -2.411273717880249, -3.3383424282073975, -3.58536696434021, -3.742725133895874, -4.030153274536133, -4.142063140869141, -4.187551498413086], [-0.7016047239303589, -1.5744932889938354, -2.4047813415527344, -2.698995590209961, -3.43536376953125, -4.593414306640625, -4.722826957702637, -4.733933448791504, -4.863555908203125, -5.002041816711426], [-0.39468827843666077, -2.5013301372528076, -2.809218168258667, -3.189476728439331, -3.5850284099578857, -4.242016315460205, -4.500250339508057, -4.92130708694458, -5.066386699676514, -5.2228264808654785], [-1.4190468788146973, -2.0943570137023926, -2.325867176055908, -2.9157586097717285, -3.215604305267334, -3.509523868560791, -3.5222840309143066, -3.566044330596924, -3.6318840980529785, -4.002583026885986], [-1.0168665647506714, -1.5224722623825073, -2.0276927947998047, -2.5917530059814453, -3.6619033813476562, -3.7813282012939453, -4.006671905517578, -4.077079772949219, -4.23524284362793, -4.543123245239258], [-1.2026854753494263, -1.4239073991775513, -2.327639579772949, -2.513321876525879, -2.8565263748168945, -3.392216682434082, -3.5182504653930664, -4.01339054107666, -4.307904243469238, -4.322312355041504], [-0.006443557795137167, -5.602419376373291, -6.726902484893799, -7.925962924957275, -8.077128410339355, -8.150568962097168, -8.616358757019043, -9.997912406921387, -10.344176292419434, -10.495768547058105], [-1.3709182739257812, -1.4698505401611328, -2.7243919372558594, -3.4138736724853516, -3.5533809661865234, -3.9717254638671875, -4.053680419921875, -4.102090835571289, -4.132839202880859, -4.14799690246582], [-1.5864578485488892, -1.6415001153945923, -1.662234902381897, -3.257689952850342, -3.2923636436462402, -3.5311331748962402, -3.832911968231201, -3.8797640800476074, -3.8973402976989746, -4.4099555015563965], [-0.6100161075592041, -1.4191038608551025, -2.5895159244537354, -3.100364923477173, -3.8423616886138916, -4.379001617431641, -4.427286148071289, -5.1265106201171875, -5.452419281005859, -5.542058944702148], [-1.04160475730896, -2.411468267440796, -2.4460370540618896, -3.448829412460327, -3.6777493953704834, -3.764463186264038, -3.8921239376068115, -3.978257894515991, -4.2839813232421875, -4.461765289306641], [-0.19126716256141663, -2.8822367191314697, -3.9111521244049072, -4.03570556640625, -4.436794281005859, -4.822362899780273, -5.019811630249023, -5.281500816345215, -5.359209060668945, -5.60069465637207], [-0.7447212338447571, -1.904677152633667, -2.015375852584839, -3.294895887374878, -3.4907538890838623, -3.573021650314331, -3.9064929485321045, -4.137738227844238, -4.3345441818237305, -4.590920448303223], [-0.48158442974090576, -1.6509188413619995, -2.307271957397461, -3.314767837524414, -4.1926727294921875, -4.893768310546875, -4.969001770019531, -5.117140769958496, -5.712461471557617, -5.759334564208984], [-2.264974000354414e-06, -13.871519088745117, -14.873767852783203, -15.762022018432617, -16.140287399291992, -16.354185104370117, -16.595775604248047, -17.0130558013916, -17.02522850036621, -17.043840408325195], [-1.6354594230651855, -2.6327528953552246, -2.9999194145202637, -3.339099407196045, -3.3736281394958496, -3.5223402976989746, -3.9985175132751465, -4.184414386749268, -4.209683895111084, -4.369621753692627], [-1.9120286703109741, -2.2564749717712402, -2.8578600883483887, -2.874732494354248, -3.2884268760681152, -3.6868510246276855, -3.739072322845459, -3.7750163078308105, -3.811829090118408, -3.8157296180725098], [-3.3646328449249268, -3.431581735610962, -3.5543434619903564, -3.681877374649048, -3.9972469806671143, -4.126712799072266, -4.219622611999512, -4.254179000854492, -4.320169448852539, -4.48636531829834], [-2.8303091526031494, -3.191040277481079, -3.2340166568756104, -3.47792649269104, -3.519313097000122, -3.5782787799835205, -3.729219675064087, -3.7430708408355713, -3.7674267292022705, -4.290622711181641], [-1.4915003776550293, -1.8793692588806152, -1.9563956260681152, -2.1796412467956543, -3.1655192375183105, -3.7800450325012207, -4.1846537590026855, -4.210958003997803, -4.268547534942627, -4.494624614715576], [-0.9225424528121948, -1.6293944120407104, -1.9869211912155151, -3.4085445404052734, -3.5529117584228516, -3.5741539001464844, -3.6069507598876953, -3.935955047607422, -4.344701766967773, -4.437112808227539], [-1.4236750602722168, -1.9059443473815918, -2.028266429901123, -2.6821131706237793, -3.391017436981201, -4.1463942527771, -4.150065898895264, -4.162603855133057, -4.317566394805908, -4.356129169464111], [-1.7205262184143066, -2.113699436187744, -2.7008233070373535, -2.954542636871338, -3.2715649604797363, -3.369762897491455, -3.786388874053955, -3.888476848602295, -4.1647419929504395, -4.181582927703857], [-1.985303282737732, -2.0094828605651855, -2.839867115020752, -3.100686550140381, -3.1628823280334473, -3.4143929481506348, -3.4841341972351074, -3.910055637359619, -4.221665859222412, -4.2287678718566895], [-1.0290608406066895, -1.892845630645752, -3.3484063148498535, -3.7112135887145996, -3.742992877960205, -4.2682366371154785, -4.357504367828369, -4.40928316116333, -4.4209208488464355, -4.651634693145752], [-1.1774741411209106, -2.263188362121582, -2.794919967651367, -3.068549156188965, -3.5003347396850586, -3.812723159790039, -3.853734016418457, -3.895989418029785, -4.018621444702148, -4.0697126388549805], [-0.20941883325576782, -4.527816295623779, -4.533273220062256, -4.640834331512451, -4.968638896942139, -5.071452617645264, -5.2356181144714355, -5.335139751434326, -5.374020099639893, -5.487914562225342], [-2.1808502674102783, -2.2608768939971924, -2.3464272022247314, -2.704005479812622, -2.8921730518341064, -3.425612688064575, -3.465125322341919, -3.5277187824249268, -3.647040605545044, -3.6779625415802], [-0.014824234880506992, -4.313608646392822, -8.136756896972656, -9.011777877807617, -9.496907234191895, -9.585315704345703, -9.803091049194336, -9.873478889465332, -10.089311599731445, -10.240411758422852], [-0.8014701008796692, -0.8577254414558411, -3.1891825199127197, -3.6187384128570557, -3.691612482070923, -5.419092655181885, -5.6043782234191895, -5.897886753082275, -5.927781581878662, -6.285572528839111], [-1.0891835689544678, -2.096374273300171, -2.406572103500366, -3.0182301998138428, -3.1711995601654053, -3.3238542079925537, -3.7387139797210693, -3.9114110469818115, -4.030250549316406, -4.236824035644531], [-0.35243484377861023, -2.498448133468628, -3.253014326095581, -3.5379855632781982, -3.689244031906128, -3.8600223064422607, -4.338392734527588, -4.691526889801025, -4.721004962921143, -4.851912021636963], [-0.9691367745399475, -2.1678061485290527, -2.743396282196045, -2.995296001434326, -3.084146022796631, -3.1409621238708496, -3.3532328605651855, -3.491034984588623, -3.5124220848083496, -3.783881664276123], [-0.35929352045059204, -1.3561882972717285, -3.6847100257873535, -4.370213031768799, -6.156113147735596, -7.694651126861572, -7.939642429351807, -8.30738353729248, -8.51401424407959, -8.64867877960205], [-0.40699148178100586, -2.6439452171325684, -2.835282802581787, -2.9933829307556152, -3.0461020469665527, -3.5009207725524902, -4.298539638519287, -4.35614538192749, -5.2173895835876465, -5.788341045379639], [-2.2623419761657715, -2.5421042442321777, -2.84718656539917, -3.1185107231140137, -3.198882579803467, -3.2241530418395996, -3.3627963066101074, -3.42201566696167, -3.6021876335144043, -3.638092517852783], [-0.3405434489250183, -2.6361939907073975, -2.919788122177124, -3.3400018215179443, -4.054610729217529, -4.140502452850342, -4.16870641708374, -4.279813289642334, -4.466720104217529, -4.781287670135498], [-0.16359175741672516, -1.9227794408798218, -5.928455829620361, -7.461325168609619, -7.820744037628174, -8.948553085327148, -9.214540481567383, -9.436592102050781, -9.472146034240723, -9.478597640991211], [-1.4309000968933105, -1.6413626670837402, -2.1517481803894043, -2.662330150604248, -3.2658724784851074, -3.5389819145202637, -3.646827220916748, -3.9103140830993652, -3.990518093109131, -4.0012898445129395], [-0.6190890073776245, -2.1201438903808594, -2.5516395568847656, -3.2124671936035156, -3.2991504669189453, -3.420804977416992, -4.148271560668945, -4.219520568847656, -4.367395401000977, -5.047178268432617], [-0.21895234286785126, -3.1015589237213135, -3.163421869277954, -3.657329797744751, -4.205699920654297, -4.555398941040039, -4.898569107055664, -5.099357604980469, -5.354625701904297, -5.474325180053711], [-0.9843940734863281, -1.5719223022460938, -2.2805233001708984, -2.5700149536132812, -2.591268539428711, -3.3988285064697266, -3.3993091583251953, -4.497323989868164, -4.606817245483398, -5.377031326293945], [-1.5075304508209229, -1.9697344303131104, -2.0383074283599854, -2.6964800357818604, -2.733368158340454, -2.8463289737701416, -3.006237268447876, -3.19978928565979, -3.924675226211548, -4.114681243896484], [-1.3885363340377808, -2.0748233795166016, -2.3812637329101562, -2.7614097595214844, -2.7728652954101562, -2.779478073120117, -2.8639392852783203, -3.142984390258789, -3.2934398651123047, -3.500581741333008], [-0.9775257110595703, -2.7014503479003906, -3.18719482421875, -3.2089290618896484, -3.2367610931396484, -3.3794002532958984, -3.605691909790039, -3.7103567123413086, -4.027187347412109, -4.238225936889648], [-0.14740021526813507, -3.3594534397125244, -3.853426218032837, -4.0677170753479, -4.5588555335998535, -4.638853549957275, -5.04394006729126, -5.0885491371154785, -5.332144260406494, -5.505804538726807], [-0.8341962695121765, -1.5679609775543213, -2.424368143081665, -2.5840494632720947, -2.6065332889556885, -3.6131861209869385, -3.958153009414673, -4.820659637451172, -5.465324401855469, -5.639255523681641], [-0.8047923445701599, -1.7644290924072266, -2.642507553100586, -2.651334762573242, -3.3848953247070312, -3.8510265350341797, -3.968852996826172, -4.556972503662109, -4.685342788696289, -4.7023468017578125], [-0.4190567433834076, -1.7882126569747925, -2.5080325603485107, -4.099024772644043, -4.662873268127441, -4.7723894119262695, -5.171238899230957, -5.288281440734863, -5.3064775466918945, -5.407830238342285], [-2.341231346130371, -2.411151885986328, -2.6807985305786133, -3.170246124267578, -3.642653465270996, -3.7319374084472656, -4.009320259094238, -4.015793800354004, -4.102328300476074, -4.131155967712402], [-0.008345610462129116, -4.980208396911621, -8.443610191345215, -8.619359970092773, -9.07816219329834, -9.575812339782715, -9.730843544006348, -9.827857971191406, -9.957014083862305, -10.036230087280273], [-1.5573090314865112, -2.411332130432129, -2.4898195266723633, -2.6186914443969727, -2.6464853286743164, -2.7922544479370117, -3.522965431213379, -3.563187599182129, -3.597376823425293, -4.00557804107666], [-1.062849998474121, -1.8274812698364258, -1.8516111373901367, -3.196782112121582, -3.3055925369262695, -3.7246522903442383, -3.796328544616699, -3.920487403869629, -4.015183448791504, -4.114354133605957], [-1.3013622760772705, -1.8083202838897705, -2.173733949661255, -2.545607805252075, -3.1877148151397705, -3.4849236011505127, -3.486830949783325, -3.5126259326934814, -3.6466705799102783, -3.665900468826294], [-1.1842525005340576, -1.4819762706756592, -1.8627135753631592, -2.512680768966675, -2.549595594406128, -3.9514052867889404, -4.358607292175293, -4.445679664611816, -4.465775489807129, -4.472857475280762], [-1.4333726167678833, -1.5362473726272583, -2.112445831298828, -2.538930892944336, -2.7034568786621094, -3.1891536712646484, -3.515911102294922, -3.596914291381836, -3.660989761352539, -3.7415008544921875], [-2.053934335708618, -2.0547945499420166, -2.137220621109009, -2.5629732608795166, -2.626751184463501, -2.780662775039673, -3.0147650241851807, -3.084707498550415, -3.3688204288482666, -3.7044622898101807], [-0.16535334289073944, -2.544839382171631, -3.5473036766052246, -4.702268123626709, -4.714568614959717, -5.384883403778076, -5.668507099151611, -5.851736545562744, -6.1869215965271, -6.6739630699157715], [-2.0437610149383545, -2.2968509197235107, -2.3585097789764404, -2.414280652999878, -2.5126426219940186, -2.8996779918670654, -3.0434348583221436, -3.2347915172576904, -3.853144407272339, -3.99359393119812], [-1.1394084692001343, -1.379738211631775, -1.7964309453964233, -2.081017017364502, -3.1433911323547363, -4.055258274078369, -4.337942600250244, -4.810680866241455, -4.814527988433838, -5.227952480316162], [-0.1377570927143097, -2.96588397026062, -4.413163185119629, -4.781376838684082, -5.178404808044434, -5.4185895919799805, -5.904202461242676, -5.927211761474609, -6.252840995788574, -6.274017333984375], [-0.013372022658586502, -5.488143444061279, -5.5687079429626465, -6.404548168182373, -8.172151565551758, -8.211648941040039, -8.554170608520508, -8.883020401000977, -8.976799011230469, -9.347463607788086], [-0.0021100416779518127, -7.119436740875244, -7.713552951812744, -8.337321281433105, -8.993660926818848, -9.45549488067627, -10.107989311218262, -10.355137825012207, -10.378920555114746, -10.416762351989746], [-0.21868416666984558, -2.1911497116088867, -3.0630006790161133, -4.212672233581543, -5.571555137634277, -5.858513832092285, -6.241036415100098, -6.760771751403809, -6.827052116394043, -6.915343284606934], [-2.379545211791992, -2.5579967498779297, -2.5955257415771484, -2.9873733520507812, -3.178983688354492, -3.1947708129882812, -3.2470455169677734, -3.4105091094970703, -3.419496536254883, -3.533008575439453], [-1.8756722211837769, -1.9865673780441284, -3.2404050827026367, -3.4529285430908203, -3.5191831588745117, -3.5563364028930664, -3.596652030944824, -3.771615982055664, -3.8643999099731445, -3.9301233291625977], [-0.592950701713562, -1.0955599546432495, -4.003713607788086, -4.110570907592773, -4.537487030029297, -5.123136520385742, -5.152637481689453, -5.370752334594727, -5.503889083862305, -5.644590377807617], [-0.48388993740081787, -2.2997488975524902, -2.7441954612731934, -3.7298293113708496, -3.8399367332458496, -3.9696974754333496, -4.077958583831787, -4.271947383880615, -4.797977924346924, -4.808274745941162], [-1.6220237016677856, -2.2037973403930664, -2.9097280502319336, -3.243037223815918, -3.256758689880371, -3.5612525939941406, -3.741720199584961, -3.7792367935180664, -3.8621416091918945, -3.8951778411865234], [-0.29804617166519165, -2.5362014770507812, -2.8745689392089844, -3.6181697845458984, -4.041509628295898, -4.105207443237305, -4.152166366577148, -4.67137336730957, -4.793924331665039, -5.495906829833984], [-0.06145072355866432, -4.017887115478516, -4.020498275756836, -4.8596343994140625, -6.489282608032227, -6.489904403686523, -6.538427352905273, -6.614845275878906, -6.823487281799316, -7.21739387512207], [-0.11467134207487106, -2.368171215057373, -5.1802077293396, -5.43359899520874, -5.517680644989014, -8.280963897705078, -9.07187557220459, -10.12823486328125, -10.197040557861328, -10.843255996704102], [-0.4992251396179199, -2.0967650413513184, -3.5482935905456543, -3.913379192352295, -3.9190688133239746, -4.067935466766357, -4.13879919052124, -4.143489360809326, -4.149583339691162, -4.167117595672607], [-1.1879252195358276, -2.145956039428711, -3.036022186279297, -3.1404247283935547, -3.557100296020508, -3.584469795227051, -3.7022571563720703, -3.8545846939086914, -3.996030807495117, -4.00937557220459], [-0.2545188069343567, -1.594484567642212, -6.438388347625732, -6.607492923736572, -6.826731204986572, -6.953978061676025, -7.1320109367370605, -7.312503337860107, -7.451691150665283, -7.74197244644165], [-1.014087438583374, -1.316180944442749, -2.4023282527923584, -2.488158941268921, -3.457031011581421, -3.705634832382202, -3.833595037460327, -4.176883697509766, -4.210151672363281, -4.999162673950195], [-1.2256664037704468, -2.0317177772521973, -2.4840149879455566, -2.531679630279541, -2.8796467781066895, -3.6380257606506348, -3.7434048652648926, -3.768547534942627, -3.8159260749816895, -3.816927433013916], [-0.6214956641197205, -1.786975383758545, -2.083034038543701, -2.460944652557373, -3.1941237449645996, -4.844954967498779, -5.430215358734131, -5.768996715545654, -5.983314037322998, -6.313582897186279], [-0.003517632372677326, -6.670958042144775, -7.263660907745361, -7.281254291534424, -8.88086986541748, -9.408350944519043, -9.817702293395996, -10.231965065002441, -10.252760887145996, -10.26668643951416], [-0.006372607313096523, -5.963470458984375, -7.181550979614258, -7.859401702880859, -8.00752067565918, -8.14647102355957, -8.661233901977539, -8.677490234375, -8.855863571166992, -9.053049087524414], [-0.9369013905525208, -1.2726786136627197, -2.229797601699829, -3.5736887454986572, -3.7176802158355713, -4.061924457550049, -4.118631839752197, -4.221745014190674, -4.274813175201416, -4.373627185821533], [-0.5815585255622864, -1.9891626834869385, -2.4084150791168213, -2.487924814224243, -3.7450010776519775, -3.7745726108551025, -4.091810703277588, -4.280825138092041, -4.775257587432861, -5.489071369171143], [-0.9555588960647583, -1.8176785707473755, -2.3882598876953125, -3.390439987182617, -3.5975399017333984, -3.8626708984375, -4.099948883056641, -4.251712799072266, -4.387123107910156, -4.541797637939453], [-1.0806386470794678, -1.4278676509857178, -2.4771764278411865, -3.007018804550171, -3.3247525691986084, -3.3833863735198975, -3.4041383266448975, -3.5318734645843506, -4.379859924316406, -4.62224006652832], [-1.3293884992599487, -1.6252964735031128, -2.5948286056518555, -2.667557716369629, -2.785944938659668, -2.889031410217285, -3.6111021041870117, -3.6282129287719727, -4.015231132507324, -4.069157600402832], [-0.300842821598053, -2.655735492706299, -3.188194751739502, -3.5758423805236816, -4.021183490753174, -4.50792932510376, -4.608194828033447, -5.0676960945129395, -5.200743198394775, -5.386862277984619], [-0.6252164840698242, -2.5815649032592773, -3.4645910263061523, -3.4943647384643555, -3.6413183212280273, -3.8400678634643555, -3.8702878952026367, -4.014073371887207, -4.307255744934082, -4.3894453048706055], [-1.0268948078155518, -1.6572964191436768, -1.6921741962432861, -2.9308598041534424, -3.52428936958313, -3.73223614692688, -3.7934162616729736, -4.300271034240723, -4.304661750793457, -4.557797431945801], [-1.393804669380188, -1.9137288331985474, -2.144472122192383, -2.2945499420166016, -2.878263473510742, -2.9096174240112305, -3.2310447692871094, -3.6144886016845703, -4.34848690032959, -4.41596794128418], [-0.8449281454086304, -1.2928117513656616, -1.4454549551010132, -3.4425253868103027, -5.462705135345459, -6.038407802581787, -6.1421074867248535, -6.265223979949951, -6.365712642669678, -6.82081937789917], [-0.6360598206520081, -2.3218822479248047, -3.2056798934936523, -3.5495662689208984, -3.8856983184814453, -4.12990665435791, -4.246743202209473, -4.302272796630859, -4.559351921081543, -4.566905975341797], [-1.2989752292633057, -2.183716058731079, -2.496206521987915, -2.8766863346099854, -2.9458811283111572, -3.0603201389312744, -3.2690699100494385, -3.572838068008423, -3.6773340702056885, -4.018716812133789], [-1.3527987003326416, -2.0447962284088135, -2.106640100479126, -2.138746500015259, -2.449768304824829, -3.231121301651001, -3.567779779434204, -3.692955255508423, -3.8214781284332275, -3.9387705326080322], [-1.9009675979614258, -2.417832374572754, -2.524786949157715, -2.619143486022949, -3.091555595397949, -3.206254005432129, -3.267582893371582, -3.271307945251465, -3.642171859741211, -3.713198661804199], [-2.2895946502685547, -2.293245315551758, -2.838968276977539, -2.8708419799804688, -2.8728370666503906, -3.139984130859375, -3.587712287902832, -3.591703414916992, -3.824063301086426, -3.8632097244262695], [-1.8864045143127441, -2.1107773780822754, -2.4243760108947754, -2.4469761848449707, -2.522066593170166, -2.562635898590088, -2.755892276763916, -2.9137253761291504, -2.9489541053771973, -3.2493653297424316], [-1.640259027481079, -2.294809579849243, -2.599409341812134, -2.635974168777466, -2.7162868976593018, -2.9348490238189697, -3.280686616897583, -3.6080219745635986, -3.7105295658111572, -3.9426348209381104], [-0.8145449757575989, -2.01308274269104, -2.4517290592193604, -2.8842623233795166, -3.2850077152252197, -3.702739953994751, -3.9922564029693604, -4.655208110809326, -4.677195072174072, -5.047743320465088], [-1.3120272159576416, -2.5393736362457275, -2.9043428897857666, -2.914980173110962, -3.2636168003082275, -3.4053728580474854, -3.5116961002349854, -3.5601980686187744, -4.115744590759277, -4.163084030151367], [-0.5543022751808167, -2.144573211669922, -3.7355785369873047, -3.8544235229492188, -3.9094810485839844, -4.000837326049805, -4.044183731079102, -4.249090194702148, -4.363016128540039, -4.487329483032227], [-1.5618475675582886, -1.8203238248825073, -1.8547133207321167, -2.5053138732910156, -2.749591827392578, -2.952169418334961, -2.9527320861816406, -3.176513671875, -3.2180519104003906, -3.880756378173828], [-1.2250218391418457, -1.5149998664855957, -1.9148240089416504, -2.7340245246887207, -3.0355496406555176, -3.5320191383361816, -3.877005100250244, -4.040491580963135, -4.310633182525635, -4.3996500968933105], [-0.6789190769195557, -0.7635195255279541, -4.90814208984375, -5.049160003662109, -6.411576271057129, -6.413003921508789, -6.696957588195801, -7.147632598876953, -7.248293876647949, -7.3221588134765625], [-1.0700960159301758, -1.5309438705444336, -2.066683769226074, -2.903172492980957, -2.95084285736084, -3.8261728286743164, -3.8936452865600586, -4.104519844055176, -4.114069938659668, -4.183293342590332], [-1.2019071578979492, -1.680943489074707, -1.8655595779418945, -2.9455556869506836, -3.0359601974487305, -3.0607004165649414, -3.145258903503418, -4.227351188659668, -4.616732597351074, -4.6861677169799805], [-1.5410012006759644, -2.221184730529785, -2.302067756652832, -2.6050310134887695, -2.7366132736206055, -3.4202394485473633, -3.644883155822754, -3.813157081604004, -4.026412010192871, -4.202288627624512], [-2.0751898288726807, -2.732605218887329, -3.062211275100708, -3.1169159412384033, -3.217320680618286, -3.246201753616333, -3.7699644565582275, -3.9649813175201416, -3.982109308242798, -3.9955570697784424], [-1.6641077995300293, -1.7262797355651855, -2.1377882957458496, -2.5260844230651855, -3.2655081748962402, -3.321275234222412, -3.395078182220459, -3.541167736053467, -3.774056911468506, -3.923081874847412], [-1.529652714729309, -1.6552668809890747, -2.6988229751586914, -2.877621650695801, -2.97202205657959, -3.1262331008911133, -3.1989641189575195, -3.225958824157715, -3.4619226455688477, -3.4832372665405273], [-1.0459599494934082, -2.6167683601379395, -2.7146458625793457, -3.0381665229797363, -3.416212558746338, -3.553833484649658, -3.9478631019592285, -4.004322528839111, -4.030764102935791, -4.094627857208252], [-1.5786395072937012, -1.7005019187927246, -2.086768627166748, -2.548827648162842, -3.1406607627868652, -3.416224956512451, -3.4879679679870605, -3.7087550163269043, -3.72786283493042, -3.780637264251709], [-1.2142813205718994, -1.4864981174468994, -2.0702860355377197, -2.237917184829712, -2.541151285171509, -2.629814386367798, -3.7940256595611572, -5.081258773803711, -5.258760452270508, -5.472982406616211], [-1.2326878309249878, -2.235257148742676, -2.905074119567871, -3.264521598815918, -3.333470344543457, -3.4323339462280273, -3.4794912338256836, -3.842914581298828, -3.883284568786621, -3.9602270126342773], [-1.5750229358673096, -1.7726662158966064, -2.2198784351348877, -2.5389397144317627, -2.6817352771759033, -2.9391987323760986, -3.3964874744415283, -3.41070294380188, -3.419755220413208, -3.566594362258911], [-2.0737762451171875, -2.585794448852539, -2.778627395629883, -2.8757057189941406, -2.9342193603515625, -3.0100460052490234, -3.0774173736572266, -3.1094703674316406, -3.629037857055664, -3.815396308898926], [-0.2670969069004059, -3.2221102714538574, -3.2581915855407715, -3.741614818572998, -3.776423931121826, -4.189198970794678, -4.314708232879639, -4.5559515953063965, -4.7787089347839355, -4.90425443649292], [-0.04252270236611366, -4.090626239776611, -4.80302095413208, -5.358112812042236, -5.917164325714111, -6.451855182647705, -7.02605676651001, -7.293972492218018, -7.494722843170166, -7.880218982696533], [-1.3558663129806519, -1.6544655561447144, -1.690815806388855, -2.630986213684082, -2.99924373626709, -3.492060661315918, -3.5548391342163086, -3.8386640548706055, -3.8918561935424805, -4.253087043762207], [-0.6768916845321655, -2.8696999549865723, -3.008018970489502, -3.108725070953369, -3.6453957557678223, -3.6793370246887207, -3.697115421295166, -3.7314858436584473, -3.8582520484924316, -3.933706760406494], [-0.30600428581237793, -2.503094434738159, -3.007366895675659, -4.155468940734863, -4.270907402038574, -4.7876691818237305, -4.893528938293457, -5.180365562438965, -5.438155174255371, -5.565913200378418], [-1.3318618535995483, -1.6270831823349, -2.337843418121338, -2.6299195289611816, -2.9738259315490723, -3.827293872833252, -3.9966721534729004, -4.075584888458252, -4.122448444366455, -4.253658771514893], [-1.3861416578292847, -1.6411770582199097, -1.9548901319503784, -2.3766565322875977, -2.6117658615112305, -2.7645254135131836, -4.002469062805176, -4.161459922790527, -4.215767860412598, -4.275956153869629], [-0.5059332847595215, -2.0221457481384277, -2.1355490684509277, -2.611968517303467, -3.772874355316162, -4.793416500091553, -4.858150005340576, -5.340207576751709, -5.432956218719482, -5.755996227264404], [-0.26411545276641846, -2.6323423385620117, -3.374648094177246, -3.7249937057495117, -3.9307966232299805, -4.612496376037598, -4.843043327331543, -4.957034111022949, -4.99765682220459, -5.229578971862793], [-0.05315103754401207, -3.043734550476074, -6.14449405670166, -8.19599437713623, -8.313948631286621, -8.543329238891602, -8.733235359191895, -8.738729476928711, -8.7465238571167, -9.541193962097168], [-1.311301275563892e-06, -14.197688102722168, -15.377030372619629, -16.212190628051758, -17.130922317504883, -17.276391983032227, -17.535573959350586, -17.76140022277832, -17.80382537841797, -17.836790084838867], [-0.09798060357570648, -4.065792083740234, -5.852970123291016, -6.234079360961914, -6.3230791091918945, -6.802776336669922, -6.809682846069336, -6.976083755493164, -7.235165596008301, -7.319363594055176], [-1.2147133350372314, -2.183415651321411, -2.4587528705596924, -2.536205530166626, -3.3293440341949463, -3.51210618019104, -3.636370897293091, -3.8001015186309814, -4.017144203186035, -4.097817420959473], [-0.1706557422876358, -2.9777045249938965, -3.8031535148620605, -4.218865871429443, -5.008181095123291, -5.050995349884033, -5.266881465911865, -5.525601863861084, -5.562106609344482, -5.578945636749268], [-2.6233367919921875, -2.6393585205078125, -3.129007339477539, -3.423727035522461, -3.4996795654296875, -3.50362491607666, -3.5053892135620117, -3.807925224304199, -3.874070167541504, -3.876217842102051], [-1.7487434148788452, -2.5956501960754395, -2.6654324531555176, -3.4863266944885254, -4.070456027984619, -4.096225261688232, -4.139676570892334, -4.166045665740967, -4.1684794425964355, -4.314071178436279], [-0.7912275195121765, -0.9957258105278015, -3.2463018894195557, -4.500043869018555, -5.030648231506348, -5.216025352478027, -5.235477447509766, -5.240943908691406, -5.273937225341797, -5.397714614868164], [-1.4416061639785767, -1.9662243127822876, -1.9673839807510376, -2.2417712211608887, -2.5926527976989746, -2.953334331512451, -3.336097240447998, -4.103597164154053, -4.113137722015381, -4.264907360076904], [-1.0887531042099, -1.2450469732284546, -2.0640759468078613, -3.003387928009033, -3.340292453765869, -3.7000012397766113, -4.64116907119751, -4.832285404205322, -4.911732196807861, -4.922995090484619], [-1.231666088104248, -1.3123564720153809, -2.2917380332946777, -3.9263453483581543, -3.931750774383545, -3.987433910369873, -4.022868633270264, -4.024770259857178, -4.299468517303467, -4.339681148529053], [-0.7299951910972595, -1.4705424308776855, -2.160348415374756, -3.136704921722412, -4.560367107391357, -4.564235210418701, -4.707601070404053, -4.751147747039795, -4.856667995452881, -4.979659557342529], [-0.4962117373943329, -1.799344778060913, -3.415231466293335, -3.416656255722046, -3.44492506980896, -3.670579671859741, -4.0951762199401855, -5.238559246063232, -5.386025905609131, -5.415120601654053], [-0.6911253929138184, -2.2774882316589355, -2.849208354949951, -3.18458890914917, -3.6797919273376465, -3.7650046348571777, -3.966886043548584, -4.269301891326904, -4.439751148223877, -4.460072994232178], [-0.6048324108123779, -2.0947425365448, -2.6209876537323, -2.6332004070281982, -3.4442431926727295, -3.599196195602417, -3.725487470626831, -4.600604057312012, -4.65120792388916, -4.6804609298706055], [-1.3402694463729858, -2.04771089553833, -3.257885456085205, -3.668610095977783, -3.770362377166748, -3.956442356109619, -4.055511951446533, -4.071633815765381, -4.0764546394348145, -4.407598972320557], [-1.069621205329895, -2.3129682540893555, -2.403439521789551, -2.986912727355957, -3.0854063034057617, -3.1699037551879883, -3.374359130859375, -3.391305923461914, -4.394352912902832, -4.613873481750488], [-2.6717069149017334, -2.979469060897827, -3.3557422161102295, -3.5563361644744873, -4.096692085266113, -4.154264450073242, -4.262424468994141, -4.365462303161621, -4.386223793029785, -4.498660087585449], [-2.9533019065856934, -3.2490906715393066, -3.2908873558044434, -3.393723964691162, -3.7976174354553223, -4.143637180328369, -4.2051215171813965, -4.2552924156188965, -4.279369831085205, -4.299283504486084], [-0.2874092757701874, -3.4913182258605957, -3.939831256866455, -4.021572589874268, -4.0572991371154785, -4.288328647613525, -4.458597660064697, -4.773886203765869, -4.95095682144165, -5.121439456939697], [-0.15208090841770172, -2.9273037910461426, -3.5636677742004395, -4.114363193511963, -4.905128002166748, -5.421308994293213, -5.459167957305908, -6.427378177642822, -6.5772480964660645, -6.635033130645752], [-0.14614377915859222, -2.5071418285369873, -3.465500593185425, -4.442181587219238, -4.643797874450684, -7.646014213562012, -8.623826026916504, -9.076483726501465, -9.993711471557617, -10.028619766235352], [-9.536738616588991e-07, -14.952256202697754, -15.332221031188965, -15.586373329162598, -16.90985107421875, -17.050365447998047, -18.10201644897461, -18.130098342895508, -18.144649505615234, -18.189624786376953], [-0.5040951371192932, -1.4447383880615234, -2.794187545776367, -3.7820615768432617, -5.152783393859863, -5.251420974731445, -5.886383056640625, -6.060520172119141, -6.166250228881836, -6.307562828063965], [-3.562856435775757, -3.6714274883270264, -3.7629992961883545, -3.7845351696014404, -3.88861346244812, -3.8890674114227295, -3.9616382122039795, -4.163845062255859, -4.355118751525879, -4.363202095031738], [-0.9698226451873779, -2.020430326461792, -2.687554121017456, -3.419274091720581, -3.4409892559051514, -3.521042585372925, -3.7480533123016357, -4.062737464904785, -4.150533676147461, -4.266417503356934], [-1.6688207387924194, -1.774741530418396, -2.244157314300537, -3.0513815879821777, -3.063127040863037, -3.4790940284729004, -3.675652027130127, -3.7018485069274902, -3.7913107872009277, -3.818620204925537], [-0.6141289472579956, -1.918782114982605, -3.073348045349121, -3.265446662902832, -3.9667348861694336, -4.0348100662231445, -4.039917945861816, -4.398791313171387, -4.557102203369141, -4.831811904907227], [-2.175747871398926, -2.4352598190307617, -3.203455924987793, -3.8187475204467773, -3.867438316345215, -3.93062686920166, -3.9839563369750977, -4.111081123352051, -4.1635332107543945, -4.20449161529541], [-1.1672518253326416, -2.402284860610962, -2.844317674636841, -3.014780282974243, -3.1001198291778564, -3.145866632461548, -3.2188303470611572, -4.085003852844238, -4.2540130615234375, -4.334564208984375], [-0.5320661067962646, -2.2450883388519287, -3.3114335536956787, -3.7742793560028076, -4.094143867492676, -4.365869522094727, -4.534235954284668, -4.54058837890625, -4.751258850097656, -4.825284957885742], [-1.0412142276763916, -1.3883459568023682, -2.03121018409729, -2.101576089859009, -2.9826948642730713, -3.917066812515259, -4.790323257446289, -4.79796028137207, -4.8094482421875, -4.9274139404296875], [-1.7591943740844727, -2.7394094467163086, -2.8581600189208984, -2.981508255004883, -3.1513099670410156, -3.204983711242676, -3.4706716537475586, -3.653496742248535, -3.904240608215332, -3.9555158615112305], [-1.1746307611465454, -1.3002411127090454, -2.167050838470459, -2.434873104095459, -2.816504955291748, -3.551492214202881, -4.254113674163818, -4.5699591636657715, -4.821096897125244, -5.131561756134033], [-2.2889609336853027, -2.430182933807373, -2.979097843170166, -3.538939952850342, -3.5996718406677246, -3.783878803253174, -3.89174222946167, -4.0729804039001465, -4.104809284210205, -4.169780254364014], [-0.3728659749031067, -2.4599974155426025, -3.3399641513824463, -3.353435754776001, -3.687378168106079, -4.450912952423096, -4.743229389190674, -4.777603626251221, -4.833436489105225, -5.053831577301025], [-1.0383758544921875, -2.5108375549316406, -2.744762420654297, -3.065998077392578, -3.2428722381591797, -3.298910140991211, -3.602121353149414, -3.64849853515625, -3.756359100341797, -3.800445556640625], [-0.9589802622795105, -1.361694097518921, -3.2878739833831787, -4.1762166023254395, -4.250486850738525, -4.253264904022217, -4.388950824737549, -4.5255560874938965, -4.860705852508545, -4.947112560272217], [-1.3770833015441895, -1.6649117469787598, -2.4647793769836426, -2.5734620094299316, -3.1085877418518066, -3.633981227874756, -3.8614087104797363, -4.114248752593994, -4.240334987640381, -4.291944980621338], [-0.198011577129364, -3.4327642917633057, -3.5889036655426025, -3.6527884006500244, -3.8732893466949463, -4.179471969604492, -4.569860458374023, -4.618410110473633, -5.344697952270508, -5.4141998291015625], [-0.3733120560646057, -2.5383472442626953, -3.639211654663086, -4.312334060668945, -4.433324813842773, -4.753225326538086, -4.79096794128418, -4.950641632080078, -5.201292991638184, -5.214265823364258], [-0.9751753211021423, -1.3845038414001465, -2.658982753753662, -3.7268338203430176, -4.051600933074951, -4.093292713165283, -4.117105007171631, -4.549783229827881, -4.612537860870361, -4.794506549835205], [-1.3532782793045044, -1.445609211921692, -1.454703450202942, -2.5538930892944336, -3.74636173248291, -3.7693872451782227, -3.9279584884643555, -4.011492729187012, -4.486233711242676, -4.490235328674316], [-0.6919023394584656, -2.5442545413970947, -2.8040125370025635, -3.02217698097229, -3.1879770755767822, -3.2068941593170166, -3.764772653579712, -3.9709970951080322, -4.127988815307617, -4.368194580078125]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\" upon\", \" there\", \",\", \" the\", \" she\", \" on\", \" he\", \" day\", \" in\", \" night\"], [\" a\", \" an\", \" the\", \" one\", \" time\", \" some\", \" upon\", \" it\", \" two\", \" something\"], [\" time\", \" day\", \" night\", \" morning\", \" week\", \" Sunday\", \" long\", \" Wednesday\", \" dark\", \" little\"], [\",\", \" there\", \" in\", \" a\", \" was\", \" upon\", \".\", \" on\", \" the\", \" lived\"], [\" there\", \" a\", \" in\", \" two\", \" the\", \" she\", \" it\", \" Jack\", \" he\", \" Sam\"], [\" was\", \" were\", \" lived\", \" are\", \" is\", \"'s\", \",\", \" a\", \" wasn\", \" had\"], [\" a\", \" an\", \" two\", \" one\", \" something\", \" some\", \" the\", \" three\", \" his\", \" Jack\"], [\" little\", \" girl\", \" boy\", \" big\", \" brave\", \" small\", \" man\", \" young\", \" kind\", \" happy\"], [\"po\", \"no\", \"big\", \"No\", \"l\", \"h\", \"X\", \"normal\", \"love\", \"S\"], [\"ma\", \"an\", \"iff\", \"'.\", \" Tight\", \"ee\", \"'\", \"oration\", \"ious\", \"'.\\\"\"], [\"'.\", \"'\", \"'.\\\"\", \"',\", \".'\", \"',\\\"\", \".'\\\"\", \"'?\", \"sy\", \",'\"], [\"\\n\", \" He\", \" The\", \" She\", \" \", \" His\", \" But\", \" And\", \" Mom\", \" So\"], [\"\\n\", \"The\", \"John\", \"One\", \"He\", \"\\\"\", \"Tom\", \"Jack\", \"Every\", \"Tim\"], [\"The\", \"One\", \"\\\"\", \"John\", \"He\", \"Tom\", \"Tim\", \"Jack\", \"M\", \"Sam\"], [\" the\", \" night\", \" this\", \" first\", \" school\", \" that\", \" one\", \" home\", \" dinner\", \" last\"], [\" end\", \" park\", \" top\", \" store\", \" edge\", \" museum\", \" beach\", \" bottom\", \" market\", \" zoo\"], [\" of\", \",\", \" was\", \" he\", \" they\", \".\", \" for\", \" she\", \" there\", \"-\"], [\" the\", \" his\", \" a\", \" it\", \" every\", \" this\", \" each\", \" their\", \" one\", \" her\"], [\" day\", \" night\", \" game\", \" show\", \" story\", \" rock\", \" cave\", \" week\", \" year\", \" competition\"], [\",\", \" the\", \" he\", \" of\", \" they\", \" it\", \" everyone\", \" a\", \" she\", \" when\"], [\" the\", \" he\", \" a\", \" they\", \" all\", \" everyone\", \" his\", \" Jack\", \" Tim\", \" one\"], [\" was\", \" in\", \" knew\", \" said\", \" had\", \" wanted\", \" cheered\", \" thought\", \" gathered\", \" would\"], [\" a\", \" ready\", \" together\", \" up\", \" very\", \" to\", \" tired\", \" out\", \" dressed\", \" the\"], [\" of\", \" and\", \" to\", \".\", \" a\", \" from\", \",\", \" on\", \" at\", \" in\"], [\" the\", \" bed\", \" breath\", \" their\", \" town\", \" a\", \" his\", \" control\", \" play\", \" an\"], [\" cave\", \" house\", \" box\", \" rock\", \" truck\", \" car\", \" building\", \" volcano\", \" factory\", \" room\"], [\".\", \" and\", \",\", \" safely\", \" to\", \" with\", \" in\", \" for\", \" as\", \" but\"], [\" went\", \" was\", \" started\", \" saw\", \" ran\", \" the\", \" were\", \" explored\", \" headed\", \" began\"], [\" a\", \" something\", \" the\", \" an\", \" that\", \" lots\", \" some\", \" how\", \" many\", \" it\"], [\" beautiful\", \" big\", \" giant\", \" little\", \" lot\", \" bright\", \" huge\", \" small\", \" new\", \" strange\"], [\" rainbow\", \" sight\", \" crystal\", \" view\", \" sunset\", \",\", \" pearl\", \" diamond\", \" princess\", \" light\"], [\".\", \" with\", \" in\", \" that\", \" filled\", \",\", \" full\", \"!\", \" nearby\", \" below\"], [\" The\", \" They\", \" It\", \" There\", \"\\n\", \" Everyone\", \" But\", \" All\", \" Inside\", \" \"], [\" people\", \" cave\", \" fish\", \" water\", \" bear\", \" lake\", \" animals\", \" little\", \" villagers\", \" family\"], [\" was\", \" wanted\", \" said\", \" had\", \" decided\", \" thought\", \" and\", \" asked\", \" went\", \" smiled\"], [\" that\", \" a\", \" to\", \" an\", \" the\", \" how\", \" his\", \" it\", \" about\", \" its\"], [\" much\", \" many\", \" quickly\", \" valuable\", \" hard\", \"\\n\", \" that\", \" he\", \" important\", \" it\"], [\" that\", \" to\", \" lesson\", \" lessons\", \" and\", \" things\", \" valuable\", \",\", \"\\n\", \" by\"], [\" it\", \" the\", \" he\", \" you\", \" no\", \" day\", \" even\", \" everyone\", \" his\", \" if\"], [\" is\", \"'s\", \" was\", \" can\", \" pays\", \" made\", \" doesn\", \"\\ufffd\", \" could\", \" had\"], [\" important\", \" better\", \" always\", \" not\", \" okay\", \" worth\", \" best\", \" ok\", \" good\", \" nice\"], [\" to\", \" not\", \" if\", \" for\", \" than\", \" when\", \" that\", \" always\", \" in\", \" never\"], [\" be\", \" stay\", \" work\", \" share\", \" explore\", \" take\", \" have\", \" not\", \" keep\", \" leave\"], [\" away\", \" in\", \" safe\", \" out\", \" inside\", \" and\", \" where\", \" close\", \" on\", \" with\"], [\" than\", \" and\", \" in\", \".\", \",\", \" at\", \" instead\", \" on\", \" during\", \" when\"], [\" to\", \" brave\", \" sorry\", \" be\", \" alone\", \" explore\", \" get\", \" try\", \" something\", \" hide\"], [\".\", \" and\", \" for\", \" when\", \",\", \"!\", \" if\", \" it\", \" to\", \" that\"], [\"\\n\", \" The\", \" He\", \" \", \" From\", \" So\", \" Everyone\", \" And\", \" It\", \" All\"], [\"\\n\", \"<|endoftext|>\", \"Summary\", \"The\", \"Story\", \"Features\", \"Words\", \"So\", \"He\", \"Random\"], [\"\\n\", \",\", \"\\n\\n\", \"<|endoftext|>\", \".\", \" he\", \" the\", \"Story\", \".\\\"\", \" she\"], [\"\\n\", \",\", \" and\", \" stones\", \" stone\", \" things\", \" rocks\", \" rock\", \" shell\", \" jewelry\"], [\" the\", \" Jack\", \" his\", \" John\", \" a\", \" Jake\", \" Sally\", \" Joe\", \" Lucy\", \" Tim\"], [\" star\", \" special\", \" toy\", \" new\", \" diamond\", \" little\", \" ball\", \" real\", \" brave\", \" bear\"], [\" star\", \" coin\", \" diamond\", \" toy\", \" rock\", \" penny\", \" medal\", \" new\", \" stone\", \" car\"], [\".\", \" car\", \",\", \" and\", \" in\", \" that\", \" but\", \"!\", \" he\", \" from\"], [\".\", \",\", \" and\", \"!\", \" in\", \" but\", \" that\", \" he\", \" with\", \" at\"], [\"\\n\", \" He\", \" The\", \" She\", \" It\", \" So\", \" Everyone\", \" Tim\", \" Jack\", \" But\"], [\" little\", \" boy\", \" girl\", \" bear\", \" car\", \" bunny\", \" rabbit\", \" bird\", \" mouse\", \" cat\"], [\" was\", \" wanted\", \" said\", \" smiled\", \" felt\", \" and\", \" asked\", \" thought\", \" gave\", \" told\"], [\" the\", \" his\", \" Tim\", \" her\", \" rabbit\", \" Bob\", \" Lily\", \" its\", \" Sam\", \" Bunny\"], [\" were\", \" played\", \" became\", \" decided\", \" wanted\", \" both\", \" raced\", \" had\", \" thought\", \" hugged\"], [\" the\", \" his\", \" Sam\", \" her\", \" Tim\", \" him\", \" Sammy\", \" Bob\", \" Lily\", \" it\"], [\" bird\", \" owl\", \" rabbit\", \" fox\", \" squirrel\", \" mouse\", \" little\", \" car\", \" mechanic\", \" man\"], [\"ter\", \"ters\", \"in\", \"her\", \"rot\", \"ile\", \"oise\", \"ich\", \"opus\", \"ster\"], [\" for\", \" and\", \",\", \".\", \" again\", \" with\", \" by\", \"'s\", \" before\", \" every\"], [\" the\", \" being\", \" his\", \" teaching\", \" helping\", \" a\", \" saving\", \" making\", \" their\", \" letting\"], [\" so\", \" a\", \" kind\", \" honest\", \" such\", \" brave\", \" his\", \" careful\", \" the\", \" nice\"], [\" kind\", \" generous\", \" helpful\", \" brave\", \" nice\", \" honest\", \" careful\", \" friendly\", \" wise\", \" thoughtful\"], [\".\", \" and\", \",\", \" to\", \"!\", \" that\", \"er\", \" friends\", \" in\", \" with\"], [\"\\n\", \" He\", \" The\", \" They\", \" Tom\", \" From\", \" \", \" Then\", \" But\", \" \\\"\"], [\" said\", \" promised\", \" was\", \" hugged\", \" decided\", \" gave\", \" went\", \" smiled\", \" asked\", \" then\"], [\",\", \" goodbye\", \" he\", \" to\", \" it\", \" that\", \" thank\", \" \\\"\", \" the\", \" '\"], [\" \\\"\", \" \\ufffd\", \" '\", \"\\ufffd\", \"\\n\", \" ''\", \" and\", \" thank\", \" the\", \" \"], [\"I\", \"Thank\", \"You\", \"It\", \"Let\", \"We\", \"This\", \"Now\", \"That\", \"My\"], [\" are\", \"'re\", \" can\", \" must\", \" have\", \" should\", \" may\", \" will\", \" were\", \" know\"], [\" welcome\", \" a\", \" the\", \" my\", \" so\", \" very\", \" right\", \" lucky\", \" not\", \" always\"], [\"'\", \",\", \"!'\", \".'\", \"'.\", \"!\", \".\", \" my\", \" to\", \"'.\\\"\"], [\" girl\", \" boy\", \" ot\", \" fish\", \" bird\", \" duck\", \" one\", \" rabbit\", \" mouse\", \" bear\"], [\".\", \",\", \"!\", \".\\\"\", \" into\", \"!'\", \".'\", \"'.\", \"ling\", \" and\"], [\" I\", \" Let\", \" You\", \" Come\", \" It\", \" Now\", \" Be\", \"\\n\", \" Please\", \" What\"], [\" you\", \" someone\", \" I\", \" the\", \" we\", \" he\", \" anyone\", \" a\", \" your\", \" Tom\"], [\" need\", \" feel\", \"'re\", \" want\", \" are\", \" have\", \" can\", \" see\", \" lose\", \" like\"], [\" feeling\", \" in\", \" scared\", \" sad\", \" happy\", \" lost\", \" near\", \" worried\", \" thirsty\", \" upset\"], [\",\", \" or\", \" of\", \" and\", \" you\", \" to\", \" I\", \".\", \" in\", \".\\\"\"], [\" don\", \" you\", \" lonely\", \" alone\", \" swim\", \" I\", \" sad\", \" stay\", \" we\", \" the\"], [\"'t\", \"\\ufffd\", \"\\u00b4\", \"t\", \"uts\", \"'\", \" have\", \"\\n\", \"'ll\", \" get\"], [\" know\", \" go\", \" have\", \" be\", \" come\", \" want\", \" feel\", \" get\", \" run\", \" do\"], [\" back\", \" near\", \" out\", \" to\", \" up\", \" close\", \" closer\", \" here\", \" in\", \" too\"], [\" with\", \"!\\\"\", \".\\\"\", \" again\", \" for\", \" here\", \" too\", \"!\", \" behind\", \" to\"], [\".\\\"\", \",\", \"!\\\"\", \"\\\".\", \".\", \" and\", \" to\", \"!\", \" like\", \"!\\\".\"], [\" to\", \" the\", \" that\", \" how\", \" this\", \" you\", \" and\", \" his\", \" what\", \" your\"], [\",\\\"\", \".\\\"\", \" and\", \".\", \",\", \"!\\\"\", \" when\", \"\\\".\", \"!\", \" to\"], [\"\\n\", \" \", \" The\", \" Tom\", \" So\", \" And\", \" He\", \" From\", \" Then\", \" They\"], [\" stayed\", \" all\", \" hugged\", \" became\", \" both\", \" were\", \" would\", \" played\", \" smiled\", \" continued\"], [\" the\", \" good\", \" best\", \" friends\", \" very\", \" better\", \" great\", \" fast\", \" a\", \" even\"], [\" best\", \" happiest\", \" most\", \" little\", \" duck\", \" ot\", \" smartest\", \" brav\", \" fish\", \" might\"], [\" of\", \" ot\", \" friends\", \" friend\", \" at\", \" duck\", \" swim\", \" little\", \" sw\", \" animal\"], [\" friends\", \" pals\", \" buddies\", \" friend\", \" the\", \" brothers\", \" each\", \" companions\", \" all\", \" siblings\"], [\" and\", \".\", \",\", \"!\", \" who\", \" after\", \" again\", \" forever\", \" in\", \" but\"], [\" stayed\", \" would\", \" the\", \" always\", \" lived\", \" played\", \" went\", \" had\", \" they\", \" were\"], [\" looked\", \" stayed\", \" helped\", \" made\", \" said\", \" stays\", \" played\", \" remembered\", \" shared\", \" protected\"], [\" the\", \" each\", \" Tom\", \" new\", \" others\", \" those\", \" him\", \" a\", \" everyone\", \" their\"], [\" the\", \" their\", \".\", \" to\", \" for\", \" with\", \" a\", \" each\", \" and\", \" all\"], [\" cave\", \" forest\", \" park\", \" me\", \" sunshine\", \" lake\", \" end\", \" river\", \" warm\", \" fun\"], [\".\", \" with\", \" whenever\", \" to\", \" by\", \" when\", \" for\", \" together\", \",\", \"!\"], [\"\\n\", \" \", \" The\", \" They\", \" From\", \" And\", \" Whenever\", \" He\", \" Tom\", \" It\"], [\"Summary\", \"\\n\", \"Story\", \"Words\", \"Features\", \"The\", \" \", \"Random\", \"One\", \"Tom\"], [\"The\", \"One\", \"Tom\", \"They\", \"Soon\", \"From\", \"And\", \"At\", \"When\", \"After\"], [\" and\", \" was\", \" stayed\", \" learned\", \" never\", \" smiled\", \"'s\", \" soon\", \" is\", \" had\"], [\" the\", \" his\", \" Sam\", \" Mom\", \" Tom\", \" all\", \" Jack\", \" Sue\", \" this\", \" Ben\"], [\" ot\", \" duck\", \" little\", \" bear\", \" fox\", \" lake\", \" other\", \" fish\", \" ducks\", \" baby\"], [\" stayed\", \" were\", \" had\", \" became\", \" played\", \" went\", \" spent\", \" kept\", \" continued\", \" would\"], [\" lots\", \" a\", \" so\", \" many\", \" fun\", \" the\", \" such\", \" become\", \" been\", \" learned\"], [\" of\", \" to\", \" and\", \" more\", \" lots\", \" fun\", \" happy\", \",\", \" in\", \" every\"], [\" fun\", \" adventures\", \" wonderful\", \" lovely\", \" happy\", \" great\", \" love\", \" friends\", \" exciting\", \" nice\"], [\" playing\", \" together\", \" swimming\", \" in\", \".\", \" and\", \" spl\", \" exploring\", \" with\", \" every\"], [\".\", \",\", \" and\", \" in\", \" every\", \" at\", \" on\", \"!\", \" playing\", \" with\"], [\" and\", \" playing\", \" swimming\", \" exploring\", \" but\", \" always\", \" until\", \" learning\", \" even\", \" making\"], [\" the\", \" they\", \" Tom\", \" he\", \" when\", \" soon\", \" every\", \" it\", \" were\", \" whenever\"], [\" were\", \" never\", \" both\", \" stayed\", \" always\", \" lived\", \" all\", \" even\", \" would\", \" played\"], [\" the\", \" many\", \" every\", \" all\", \" and\", \".\", \" new\", \" more\", \" a\", \" caves\"], [\" lake\", \" cave\", \" forest\", \" world\", \" beautiful\", \" deep\", \" new\", \" river\", \" wonders\", \" woods\"], [\".\", \" and\", \" every\", \" together\", \" with\", \",\", \" for\", \" until\", \" many\", \" all\"], [\" They\", \" Tom\", \" Whenever\", \" Every\", \"\\n\", \" The\", \" It\", \" He\", \" From\", \" When\"], [\" were\", \" was\", \",\", \" they\", \" the\", \" are\", \" would\", \" and\", \" it\", \"'s\"], [\" they\", \" the\", \" Tom\", \" in\", \" were\", \" was\", \" always\", \" it\", \" on\", \" he\"], [\" found\", \" saw\", \" met\", \" discovered\", \" even\", \" were\", \" would\", \" made\", \" learned\", \" shared\"], [\" a\", \" lots\", \" something\", \" that\", \" many\", \" new\", \" the\", \" all\", \" some\", \" so\"], [\" new\", \" secret\", \" beautiful\", \" big\", \" wonderful\", \" treasure\", \" family\", \" lot\", \" special\", \" cozy\"], [\" place\", \" treasure\", \" secret\", \" room\", \" surprise\", \" cave\", \" lake\", \" spot\", \" new\", \" waterfall\"], [\" that\", \" in\", \".\", \" with\", \" and\", \" where\", \" called\", \" to\", \" full\", \" for\"], [\" a\", \" even\", \" the\", \" it\", \" made\", \" lots\", \" they\", \" had\", \" all\", \" Tom\"], [\" the\", \" kinds\", \" sorts\", \" of\", \" their\", \" its\", \" was\", \" they\", \" had\", \" that\"], [\" wonderful\", \" animals\", \" other\", \" fun\", \" things\", \" treasures\", \" best\", \" toys\", \" amazing\", \" beautiful\"], [\" things\", \" sights\", \" places\", \" treasures\", \" flowers\", \" decorations\", \" toys\", \" memories\", \" animals\", \" colours\"], [\" they\", \" in\", \".\", \" that\", \" to\", \" it\", \" inside\", \" the\", \" around\", \",\"], [\" They\", \"\\n\", \" Tom\", \" The\", \" It\", \" \", \" There\", \" In\", \" When\", \" Every\"], [\"Summary\", \"\\n\", \"The\", \"Tom\", \"At\", \"They\", \" \", \"Story\", \"This\", \"Words\"], [\"The\", \"Tom\", \"At\", \"They\", \"When\", \"After\", \"In\", \"This\", \"From\", \"One\"], [\" moral\", \" end\", \" duck\", \" little\", \" ot\", \" bear\", \" End\", \" next\", \" kind\", \" cabin\"], [\" bear\", \" duck\", \" place\", \" animals\", \" cabin\", \" fox\", \" friends\", \" boy\", \" of\", \" little\"], [\" had\", \" said\", \" made\", \" were\", \" and\", \" all\", \" that\", \" never\", \"'\", \",\"], [\" so\", \" a\", \" made\", \" found\", \" been\", \" to\", \" lots\", \" never\", \" learned\", \" the\"], [\" them\", \" the\", \" everyone\", \" Tom\", \" that\", \" how\", \" their\", \" compassion\", \" kindness\", \" him\"], [\" cabin\", \" duck\", \" little\", \" way\", \" cave\", \" world\", \" value\", \" importance\", \" bear\", \" wonderful\"], [\" the\", \" duck\", \" bear\", \" ot\", \" something\", \" how\", \" that\", \" to\", \" around\", \" an\"], [\" the\", \" and\", \",\", \".\", \" them\", \" him\", \" so\", \" her\", \" a\", \" to\"], [\" they\", \" the\", \" was\", \" it\", \" everyone\", \" were\", \" taught\", \" made\", \" enjoyed\", \" explored\"], [\" the\", \" it\", \" being\", \" playing\", \" their\", \" every\", \" exploring\", \" its\", \" a\", \" life\"], [\" a\", \" together\", \" in\", \" the\", \" with\", \" there\", \" fit\", \" part\", \" so\", \" brave\"], [\".\", \",\", \" in\", \" and\", \" for\", \" with\", \" by\", \" as\", \" at\", \" again\"], [\".\", \",\", \" and\", \"!\", \" in\", \" after\", \" with\", \"more\", \" as\", \" more\"], [\" They\", \"\\n\", \" Tom\", \" The\", \" It\", \" Tommy\", \" From\", \" And\", \" He\", \" Whenever\"], [\" was\", \" knew\", \" never\", \" learned\", \" also\", \" learnt\", \" thanked\", \" felt\", \" even\", \" had\"], [\" forgot\", \" felt\", \" wanted\", \" stopped\", \" regretted\", \" got\", \" had\", \" knew\", \" expected\", \" left\"], [\" it\", \" his\", \" being\", \" anything\", \" not\", \" having\", \" this\", \" the\", \" going\", \" what\"], [\".\", \" and\", \" before\", \" again\", \",\", \"!\", \" when\", \" as\", \" -\", \" ever\"], [\".\", \" and\", \"!\", \",\", \" because\", \" -\", \" to\", \" when\", \" but\", \" as\"], [\"\\n\", \" He\", \" The\", \" \", \" From\", \" His\", \" But\", \" They\", \" Whenever\", \" It\"], [\"Summary\", \"\\n\", \"The\", \"Story\", \"Words\", \" \", \"This\", \"Features\", \"M\", \"Tom\"], [\"\\n\", \"\\n\\n\", \",\", \".\", \".\\\"\", \" the\", \"<|endoftext|>\", \" The\", \",\\\"\", \" \"], [\"\\n\", \",\", \" and\", \" The\", \" Bad\", \"Summary\", \" house\", \" \", \" Bob\", \"Words\"], [\" the\", \" his\", \" with\", \" and\", \",\", \" a\", \" every\", \" to\", \"!\", \" him\"], [\" the\", \" his\", \" of\", \" kinds\", \" her\", \" these\", \" different\", \" those\", \" their\", \" sorts\"], [\" other\", \" fun\", \" wonderful\", \" animals\", \" places\", \" new\", \" different\", \" special\", \" way\", \" time\"], [\" animals\", \" books\", \" places\", \" children\", \" park\", \" fun\", \" rooms\", \" kids\", \" camp\", \" people\"], [\" places\", \" things\", \" and\", \" games\", \" animals\", \" activities\", \" creatures\", \" times\", \" people\", \" rooms\"], [\" and\", \",\", \".\", \" he\", \" in\", \" the\", \" around\", \" to\", \" before\", \" that\"], [\"'d\", \" had\", \" could\", \" would\", \" can\", \" visited\", \" wanted\", \" has\", \" will\", \" never\"], [\" go\", \" explore\", \" visit\", \" find\", \" have\", \" enjoy\", \" see\", \" travel\", \" play\", \" ever\"], [\".\", \" and\", \",\", \" with\", \" whenever\", \"!\", \" when\", \" from\", \" if\", \" in\"], [\" the\", \" her\", \" his\", \" a\", \" their\", \" this\", \" one\", \" spring\", \" an\", \" special\"], [\" day\", \" next\", \" time\", \" holiday\", \" night\", \" summer\", \" holidays\", \" tour\", \" fun\", \" show\"], [\".\", \" and\", \" of\", \",\", \"!\", \" too\", \" she\", \" when\", \" to\", \" with\"], [\" and\", \" but\", \" she\", \" until\", \" making\", \" looking\", \" feeling\", \" knowing\", \" learning\", \" always\"], [\" she\", \" they\", \" the\", \" her\", \" was\", \" he\", \" even\", \" it\", \" is\", \" never\"], [\" little\", \" old\", \" baby\", \" big\", \" people\", \" other\", \" next\", \" small\", \" family\", \" memories\"], [\" day\", \" world\", \" things\", \" garden\", \" landscape\", \" view\", \" sunset\", \" summer\", \" country\", \" sights\"], [\".\", \" was\", \",\", \" with\", \" to\", \" and\", \" she\", \" in\", \"!\", \" before\"], [\"\\n\", \" She\", \" He\", \" The\", \" \", \" It\", \" They\", \" Everyone\", \" Every\", \" When\"], [\"Summary\", \"Story\", \"Words\", \"Features\", \"\\n\", \"The\", \"Random\", \" \", \"One\", \"This\"], [\"\\n\", \",\", \"\\n\\n\", \".\", \".\\\"\", \" the\", \",\\\"\", \":\", \" \\\"\", \"?\\\"\"], [\"ly\", \"\\n\", \" and\", \",\", \" the\", \" little\", \".\", \" with\", \"!\", \" as\"], [\" explores\", \" decided\", \" stepped\", \" explored\", \",\", \" went\", \" said\", \" looked\", \" made\", \" walked\"], [\"um\", \"es\", \"acks\", \"is\", \"avi\", \"ures\", \"u\", \"ies\", \"v\", \"oot\"], [\"ip\", \"ys\", \"ad\", \"ies\", \"icking\", \"ily\", \"ures\", \"t\", \"icked\", \"am\"], [\" the\", \" her\", \" it\", \" his\", \" up\", \" a\", \" its\", \" some\", \" and\", \" their\"], [\" cater\", \" rabbit\", \" bunny\", \" bird\", \" fox\", \" snake\", \" spider\", \" vine\", \" nut\", \" frog\"], [\"'s\", \" and\", \",\", \" rabbit\", \" bird\", \" until\", \" to\", \".\", \" bunny\", \"\\ufffd\"], [\" hand\", \" face\", \" finger\", \" hands\", \" paw\", \" nose\", \" shoulder\", \" head\", \" mom\", \" heel\"], [\" and\", \",\", \".\", \" to\", \" with\", \"!\", \" in\", \" as\", \" again\", \" when\"], [\" the\", \" said\", \" smiled\", \" he\", \" they\", \" she\", \" was\", \" thanked\", \" it\", \" a\"], [\" the\", \" him\", \" it\", \" her\", \" his\", \" them\", \" its\", \" everyone\", \" for\", \" each\"], [\" old\", \" owl\", \" bird\", \" bear\", \" tree\", \" man\", \" fox\", \" wise\", \" fairy\", \" mom\"], [\" for\", \".\", \" before\", \" keeper\", \" again\", \",\", \" every\", \" with\", \" once\", \"'s\"], [\" the\", \" a\", \" being\", \" all\", \" taking\", \" its\", \" letting\", \" showing\", \" helping\", \" his\"], [\" fun\", \" wonderful\", \" adventure\", \" gift\", \" special\", \" amazing\", \" invitation\", \" lovely\", \" beautiful\", \" great\"], [\" day\", \" experience\", \" time\", \" adventure\", \" surprise\", \" gift\", \" things\", \" show\", \" sight\", \" journey\"], [\".\", \" he\", \" she\", \" it\", \" they\", \" with\", \",\", \" together\", \" before\", \" and\"], [\" had\", \" was\", \" spent\", \" said\", \" felt\", \" already\", \" left\", \"'d\", \" could\", \" made\"], [\".\", \" with\", \" in\", \" there\", \" on\", \" spent\", \" at\", \" done\", \" and\", \" the\"], [\".\", \" it\", \" the\", \" all\", \" so\", \" and\", \" something\", \" that\", \" everything\", \" him\"], [\" so\", \".\", \" special\", \" truly\", \" that\", \" very\", \" she\", \" new\", \" wonderful\", \" beautiful\"]], \"correctTokenRank\": [294, 0, 0, 0, 0, 0, 0, 0, 1474, 105, 150, 2, 0, 0, 24, 0, 0, 0, 0, 0, 0, 5, 27, 7, 0, 0, 0, 1, 3, 0, 0, 20, 0, 0, 4, 82, 12, 3, 0, 0, 1, 1, 0, 1, 2, 0, 2, 0, 0, 1, 1217, 522, 4, 794, 3, 1, 0, 2, 3, 5, 14, 31, 0, 64, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 1, 0, 16, 5, 0, 53, 0, 2, 2, 3, 0, 0, 4, 4, 29, 311, 5, 1, 9, 3, 0, 0, 0, 0, 0, 3, 12, 16, 0, 5, 0, 0, 1, 2, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 1, 18, 0, 165, 0, 44, 2, 0, 3, 0, 8, 0, 4, 8, 0, 9, 0, 2, 1, 1, 0, 167, 6, 0, 22, 1, 17, 8, 1, 8, 2, 1, 12, 0, 8, 2, 4, 0, 3, 0, 0, 212, 1455, 2489, 11, 0, 0, 85, 0, 14, 2, 2, 44, 0, 45, 3, 0, 2, 27, 12, 0, 0, 2327, 844, 0, 9166, 208, 8, 0, 103, 0, 1, 0, 7, 0, 894, 0, 0, 1, 2, 2, 0, 14, 6, 0], \"correctTokenLogProb\": [-11.625463485717773, -0.37248945236206055, -0.005904612597078085, -0.011737924069166183, -0.18781612813472748, -0.10250573605298996, -0.13827048242092133, -0.03213061764836311, -11.718913078308105, -6.342620372772217, -6.926331520080566, -3.7856063842773438, -1.1125653982162476, -0.38108062744140625, -5.160467624664307, -0.4633193612098694, -1.4594554901123047, -0.0895572230219841, -0.1588805615901947, -0.731742262840271, -0.03783838450908661, -3.5648996829986572, -5.197713375091553, -3.077122449874878, -0.0938071459531784, -0.34039992094039917, -1.5050431489944458, -0.8737682700157166, -3.0611910820007324, -0.6200908422470093, -1.9465820789337158, -4.688539981842041, -0.09932177513837814, -1.1424922943115234, -3.1371965408325195, -6.908969402313232, -5.3447723388671875, -2.698995590209961, -0.39468827843666077, -1.4190468788146973, -1.5224722623825073, -1.4239073991775513, -0.006443557795137167, -1.4698505401611328, -1.662234902381897, -0.6100161075592041, -2.4460370540618896, -0.19126716256141663, -0.7447212338447571, -1.6509188413619995, -24.996129989624023, -8.658008575439453, -3.2884268760681152, -8.878491401672363, -3.47792649269104, -1.8793692588806152, -0.9225424528121948, -2.028266429901123, -2.954542636871338, -3.4143929481506348, -4.814263820648193, -5.622045516967773, -0.20941883325576782, -6.679694175720215, -0.014824234880506992, -0.8014701008796692, -2.096374273300171, -0.35243484377861023, -0.9691367745399475, -0.35929352045059204, -2.6439452171325684, -2.2623419761657715, -0.3405434489250183, -5.928455829620361, -2.1517481803894043, -2.1201438903808594, -0.21895234286785126, -6.078092575073242, -2.8463289737701416, -1.3885363340377808, -6.402237892150879, -0.14740021526813507, -2.424368143081665, -2.642507553100586, -4.099024772644043, -2.341231346130371, -0.008345610462129116, -2.6464853286743164, -3.3055925369262695, -6.210322380065918, -12.009971618652344, -3.1891536712646484, -2.0547945499420166, -6.6739630699157715, -2.414280652999878, -1.1394084692001343, -0.1377570927143097, -0.013372022658586502, -0.0021100416779518127, -0.21868416666984558, -2.9873733520507812, -4.173286437988281, -6.474881172180176, -0.48388993740081787, -3.5612525939941406, -0.29804617166519165, -0.06145072355866432, -2.368171215057373, -3.5482935905456543, -1.1879252195358276, -0.2545188069343567, -1.316180944442749, -2.4840149879455566, -0.6214956641197205, -0.003517632372677326, -0.006372607313096523, -1.2726786136627197, -1.9891626834869385, -0.9555588960647583, -1.4278676509857178, -4.988385200500488, -0.300842821598053, -8.779975891113281, -1.0268948078155518, -6.80126953125, -1.4454549551010132, -0.6360598206520081, -2.8766863346099854, -1.3527987003326416, -3.642171859741211, -2.2895946502685547, -2.522066593170166, -3.7105295658111572, -0.8145449757575989, -4.163084030151367, -0.5543022751808167, -1.8547133207321167, -1.5149998664855957, -0.7635195255279541, -1.0700960159301758, -9.045127868652344, -3.644883155822754, -2.0751898288726807, -5.2789835929870605, -1.6552668809890747, -4.75623083114624, -3.72786283493042, -1.4864981174468994, -3.883284568786621, -2.2198784351348877, -2.585794448852539, -5.461617946624756, -0.04252270236611366, -3.8918561935424805, -3.008018970489502, -4.270907402038574, -1.3318618535995483, -2.3766565322875977, -0.5059332847595215, -0.26411545276641846, -15.504415512084961, -26.216257095336914, -12.782751083374023, -4.214999198913574, -0.1706557422876358, -2.6233367919921875, -6.5181660652160645, -0.7912275195121765, -4.69319486618042, -2.0640759468078613, -2.2917380332946777, -7.682498455047607, -0.4962117373943329, -6.630829334259033, -2.6332004070281982, -1.3402694463729858, -2.403439521789551, -5.224801063537598, -4.315807819366455, -0.2874092757701874, -0.15208090841770172, -17.488492965698242, -25.52690887451172, -0.5040951371192932, -14.513956069946289, -8.739832878112793, -3.7913107872009277, -0.6141289472579956, -6.421608924865723, -1.1672518253326416, -2.2450883388519287, -1.0412142276763916, -3.653496742248535, -1.1746307611465454, -9.90251350402832, -0.3728659749031067, -1.0383758544921875, -1.361694097518921, -2.4647793769836426, -3.5889036655426025, -0.3733120560646057, -5.033483028411865, -3.9279584884643555, -0.6919023394584656]}\n",
              "    )\n",
              "    </script>"
            ],
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x30238fb90>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_prompt = model.generate(\n",
        "    \"Once upon a time\",\n",
        "    stop_at_eos=False,  # avoids a bug on MPS\n",
        "    temperature=1,\n",
        "    verbose=True,\n",
        "    max_new_tokens=200,\n",
        ")\n",
        "logits, cache = model.run_with_cache(example_prompt)\n",
        "cv.logits.token_log_probs(\n",
        "    model.to_tokens(example_prompt),\n",
        "    model(example_prompt)[0].log_softmax(dim=-1),\n",
        "    model.to_string,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er3H1TDoOVHw"
      },
      "source": [
        "# Training an SAE\n",
        "\n",
        "Now we're ready to train out SAE. We'll make a runner config, instantiate the runner and the rest is taken care of for us!\n",
        "\n",
        "During training, you use weights and biases to check key metrics which indicate how well we are able to optimize the variables we care about.\n",
        "\n",
        "To get a better sense of which variables to look at, you can read my (Joseph's) post [here](https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream) and especially look at my weights and biases report [here](https://links-cdn.wandb.ai/wandb-public-images/links/jbloom/uue9i416.html).\n",
        "\n",
        "A few tips:\n",
        "- Feel free to reorganize your wandb dashboard to put L0, CE_Loss_score, explained variance and other key metrics in one section at the top.\n",
        "- Make a [run comparer](https://docs.wandb.ai/guides/app/features/panels/run-comparer) when tuning hyperparameters.\n",
        "- You can download the resulting sparse autoencoder / sparsity estimate from wandb and upload them to huggingface if you want to share your SAE with other.\n",
        "    - cfg.json (training config)\n",
        "    - sae_weight.safetensors (model weights)\n",
        "    - sparsity.safetensors (sparsity estimate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCHtPycOOVHw"
      },
      "source": [
        "## MLP Out\n",
        "\n",
        "I've tuned the hyperparameters below for a decent SAE which achieves 86% CE Loss recovered and an L0 of ~85, and runs in about 2 hours on an M3 Max. You can get an SAE that looks better faster if you only consider L0 and CE loss but it will likely have more dense features and more dead features. Here's a link to my output with two runs with two different L1's: https://wandb.ai/jbloom/sae_lens_tutorial ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oAsZCAdJOVHw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
            "n_tokens_per_buffer (millions): 0.262144\n",
            "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
            "Total training steps: 30000\n",
            "Total wandb updates: 1000\n",
            "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
            "n_tokens_per_dead_feature_window (millions): 1048.576\n",
            "We will reset the sparsity calculation 30 times.\n",
            "Number tokens in sparsity calculation window: 4.10e+06\n",
            "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading readme: 100%|██████████| 415/415 [00:00<00:00, 4.30MB/s]\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcurt-tigges\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/curttigges/projects/SAELens/tutorials/wandb/run-20240610_114538-yr1gvjdc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/curt-tigges/sae_lens_tutorial/runs/yr1gvjdc' target=\"_blank\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/curt-tigges/sae_lens_tutorial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/curt-tigges/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/curt-tigges/sae_lens_tutorial</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/curt-tigges/sae_lens_tutorial/runs/yr1gvjdc' target=\"_blank\">https://wandb.ai/curt-tigges/sae_lens_tutorial/runs/yr1gvjdc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Estimating norm scaling factor: 100%|██████████| 1000/1000 [00:33<00:00, 29.79it/s]\n",
            "30000| MSE Loss 187.703 | L1 156.883:   1%|          | 1228800/122880000 [42:59<70:56:28, 476.34it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▅██████████████████████████████████████</td></tr><tr><td>details/current_learning_rate</td><td>████████████████████████████████▇▇▅▅▄▃▂▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>▄▅█▇▆▆▅▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>▁▅█▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>metrics/CE_loss_score</td><td>█▂▁▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▅▆▅▅▅▅▆▅▆▆▆▆▆▆▆▅</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>█▆▇▃▄▄▃▆▆▅▃▅▅▅▅▃▄▅▅▆▄▅▃▅▃▄▅▁▅▅▆▅▆▄▆▄▆▄▅▄</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>▂▇█▆▅▅▅▅▄▄▅▆▄▄▃▄▄▄▁▃▃▃▁▄▄▂▃▂▄▂▁▃▄▃▄▂▄▂▃▄</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>▇▇▇▅▄▄▆▆▅▄▇█▆▆▄▅▆▇▁▄▄▅▁▇▆▄▅▄▆▄▂▅▇▆▇▄▇▄▅█</td></tr><tr><td>metrics/explained_variance</td><td>▅▄▁▂▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇███████</td></tr><tr><td>metrics/explained_variance_std</td><td>▁▅███▇▇▇▇▇▇▆▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▆▆▅▆</td></tr><tr><td>metrics/l0</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l2_norm</td><td>▆▅▁▃▃▂▂▃▁▅▃▃▅▆▂█▄▃▄▆▇▃▆▃▃▁▂▅▅▆▇▅▄▅▃██▃▃▃</td></tr><tr><td>metrics/l2_norm_in</td><td>▅▆▅▆▆▄▅▅▃▆▄▄▆▇▄█▄▃▅▆▇▃▆▃▃▁▂▅▅▆▇▄▅▆▃▇█▄▄▃</td></tr><tr><td>metrics/l2_ratio</td><td>▇▅▁▃▃▃▃▄▃▆▅▅▆▆▄▇▆▆▅▆▇▅▇▆▅▅▅▆▆▇▇▇▆▆▆██▆▆▆</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▁▁▅▆███▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁▁▁▁▃▆▆▆█▆█████▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▁▁▅█▁▁▁▅▅█▅█▅▅████▅▅▅████</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▂▁▁▁▁▁▁▁▂▂▁▁▂▂▂▂▂▂▄▂▂▂▃▃▄▄▄▃▃▃▄▅▆▄▄▅▆▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>5</td></tr><tr><td>details/current_learning_rate</td><td>0.0</td></tr><tr><td>details/n_training_tokens</td><td>122880000</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0</td></tr><tr><td>losses/l1_loss</td><td>31.37665</td></tr><tr><td>losses/mse_loss</td><td>187.70346</td></tr><tr><td>losses/overall_loss</td><td>344.5867</td></tr><tr><td>metrics/CE_loss_score</td><td>0.90369</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>8.30545</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>2.62867</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>2.02306</td></tr><tr><td>metrics/explained_variance</td><td>0.66377</td></tr><tr><td>metrics/explained_variance_std</td><td>0.13242</td></tr><tr><td>metrics/l0</td><td>192.95703</td></tr><tr><td>metrics/l2_norm</td><td>24.64933</td></tr><tr><td>metrics/l2_norm_in</td><td>31.38967</td></tr><tr><td>metrics/l2_ratio</td><td>0.77361</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-2.66941</td></tr><tr><td>sparsity/below_1e-5</td><td>2</td></tr><tr><td>sparsity/below_1e-6</td><td>2</td></tr><tr><td>sparsity/dead_features</td><td>2</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>0.86823</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/curt-tigges/sae_lens_tutorial/runs/yr1gvjdc' target=\"_blank\">https://wandb.ai/curt-tigges/sae_lens_tutorial/runs/yr1gvjdc</a><br/> View project at: <a href='https://wandb.ai/curt-tigges/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/curt-tigges/sae_lens_tutorial</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240610_114538-yr1gvjdc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "total_training_steps = 30_000  # probably we should do more\n",
        "batch_size = 4096\n",
        "total_training_tokens = total_training_steps * batch_size\n",
        "\n",
        "lr_warm_up_steps = 0\n",
        "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
        "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
        "\n",
        "cfg = LanguageModelSAERunnerConfig(\n",
        "    # Data Generating Function (Model + Training Distibuion)\n",
        "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
        "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
        "    hook_layer=0,  # Only one layer in the model.\n",
        "    d_in=1024,  # the width of the mlp output.\n",
        "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
        "    is_dataset_tokenized=True,\n",
        "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
        "    # SAE Parameters\n",
        "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
        "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
        "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
        "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
        "    normalize_sae_decoder=False,\n",
        "    scale_sparsity_penalty_by_decoder_norm=True,\n",
        "    decoder_heuristic_init=True,\n",
        "    init_encoder_as_decoder_transpose=True,\n",
        "    normalize_activations=\"expected_average_only_in\",\n",
        "    # Training Parameters\n",
        "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
        "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
        "    adam_beta2=0.999,\n",
        "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
        "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
        "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
        "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
        "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
        "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
        "    train_batch_size_tokens=batch_size,\n",
        "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
        "    # Activation Store Parameters\n",
        "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
        "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
        "    store_batch_size_prompts=16,\n",
        "    # Resampling protocol\n",
        "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
        "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
        "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
        "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
        "    # WANDB\n",
        "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
        "    wandb_project=\"sae_lens_tutorial\",\n",
        "    wandb_log_frequency=30,\n",
        "    eval_every_n_wandb_logs=20,\n",
        "    # Misc\n",
        "    device=device,\n",
        "    seed=42,\n",
        "    n_checkpoints=0,\n",
        "    checkpoint_path=\"checkpoints\",\n",
        "    dtype=\"float32\"\n",
        ")\n",
        "# look at the next cell to see some instruction for what to do while this is running.\n",
        "sparse_autoencoder = SAETrainingRunner(cfg).run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khR_QkAJOVHw"
      },
      "source": [
        "# TO DO: Understanding TinyStories-1L with our SAE\n",
        "\n",
        "I haven't had time yet to complete this section, but I'd love to see a PR where someones uses an SAE they trained in this tutorial to understand this model better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4sUumxZOVHw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Let's start by getting the top 10 logits for each feature\n",
        "projection_onto_unembed = sparse_autoencoder.W_dec @ model.W_U\n",
        "\n",
        "\n",
        "# get the top 10 logits.\n",
        "vals, inds = torch.topk(projection_onto_unembed, 10, dim=1)\n",
        "\n",
        "# get 10 random features\n",
        "random_indices = torch.randint(0, projection_onto_unembed.shape[0], (10,))\n",
        "\n",
        "# Show the top 10 logits promoted by those features\n",
        "top_10_logits_df = pd.DataFrame(\n",
        "    [model.to_str_tokens(i) for i in inds[random_indices]],\n",
        "    index=random_indices.tolist(),\n",
        ").T\n",
        "top_10_logits_df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
