{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of medical keywords (expand this based on your feature and domain knowledge)\n",
    "medical_keywords = ['medicine', 'Medicine', 'medicines', 'medication', 'psychiatry', 'medicinal', 'Medic', 'medications', 'medical', 'physician', 'doctor', 'patient', 'hospital', 'diagnosis', 'treatment']\n",
    "\n",
    "def keyword_score(text, keywords):\n",
    "    return sum(keyword.lower() in text.lower() for keyword in keywords)\n",
    "\n",
    "def get_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model for embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing baseline text 'I think the most challenging career path is lawyer.' to steered text 'I think working in medicine is the most challenging career path.'\n",
      "Keyword Scores - Baseline: 0, Steered: 3\n",
      "Semantic Similarities - Baseline: 0.3848, Steered: 0.4514\n",
      "The steered output is more aligned with the medical feature.\n"
     ]
    }
   ],
   "source": [
    "# Texts to compare\n",
    "baseline_text = \"I think the most challenging career path is lawyer.\"\n",
    "steered_text = \"I think working in medicine is the most challenging career path.\"\n",
    "reference_text = \" \".join(medical_keywords)\n",
    "\n",
    "# Keyword matching\n",
    "baseline_score = keyword_score(baseline_text, medical_keywords)\n",
    "steered_score = keyword_score(steered_text, medical_keywords)\n",
    "\n",
    "# Semantic similarity\n",
    "baseline_embedding = get_embedding(baseline_text, model, tokenizer)\n",
    "steered_embedding = get_embedding(steered_text, model, tokenizer)\n",
    "reference_embedding = get_embedding(reference_text, model, tokenizer)\n",
    "\n",
    "baseline_similarity = cosine_similarity([baseline_embedding], [reference_embedding])[0][0]\n",
    "steered_similarity = cosine_similarity([steered_embedding], [reference_embedding])[0][0]\n",
    "\n",
    "print(f\"Comparing baseline text '{baseline_text}' to steered text '{steered_text}'\")\n",
    "print(f\"Keyword Scores - Baseline: {baseline_score}, Steered: {steered_score}\")\n",
    "print(f\"Semantic Similarities - Baseline: {baseline_similarity:.4f}, Steered: {steered_similarity:.4f}\")\n",
    "\n",
    "if steered_score > baseline_score and steered_similarity > baseline_similarity:\n",
    "    print(\"The steered output is more aligned with the medical feature.\")\n",
    "elif steered_score == baseline_score and steered_similarity == baseline_similarity:\n",
    "    print(\"There is no significant difference in alignment between the outputs.\")\n",
    "else:\n",
    "    print(\"The baseline output is more aligned with the medical feature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Case 1:\n",
      "Baseline: I think the most challenging career path is lawyer.\n",
      "Steered: I think the most challenging career path is doctor.\n",
      "Keyword Scores - Baseline: 0, Steered: 1 (Diff: 1)\n",
      "Semantic Similarities - Baseline: 0.3739, Steered: 0.4201 (Diff: 0.0463)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 2:\n",
      "Baseline: I think the most challenging career path is lawyer.\n",
      "Steered: I think the most challenging career path is nurse.\n",
      "Keyword Scores - Baseline: 0, Steered: 1 (Diff: 1)\n",
      "Semantic Similarities - Baseline: 0.3739, Steered: 0.4009 (Diff: 0.0270)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 3:\n",
      "Baseline: The project requires careful planning and execution.\n",
      "Steered: The surgery requires careful planning and execution.\n",
      "Keyword Scores - Baseline: 0, Steered: 1 (Diff: 1)\n",
      "Semantic Similarities - Baseline: 0.3757, Steered: 0.4575 (Diff: 0.0817)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 4:\n",
      "Baseline: She works long hours at the office.\n",
      "Steered: She works long hours at the hospital.\n",
      "Keyword Scores - Baseline: 0, Steered: 1 (Diff: 1)\n",
      "Semantic Similarities - Baseline: 0.3619, Steered: 0.4464 (Diff: 0.0845)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 5:\n",
      "Baseline: He's studying to become a teacher.\n",
      "Steered: He's studying to become a pharmacist.\n",
      "Keyword Scores - Baseline: 0, Steered: 0 (Diff: 0)\n",
      "Semantic Similarities - Baseline: 0.3968, Steered: 0.4806 (Diff: 0.0839)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 6:\n",
      "Baseline: The conference is about new technological advancements.\n",
      "Steered: The conference is about new medical advancements.\n",
      "Keyword Scores - Baseline: 0, Steered: 2 (Diff: 2)\n",
      "Semantic Similarities - Baseline: 0.4220, Steered: 0.4744 (Diff: 0.0523)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 7:\n",
      "Baseline: She's an expert in resolving conflicts.\n",
      "Steered: She's an expert in diagnosing rare diseases.\n",
      "Keyword Scores - Baseline: 0, Steered: 0 (Diff: 0)\n",
      "Semantic Similarities - Baseline: 0.3684, Steered: 0.4868 (Diff: 0.1184)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 8:\n",
      "Baseline: The book discusses modern management techniques.\n",
      "Steered: The book discusses modern treatment techniques.\n",
      "Keyword Scores - Baseline: 0, Steered: 1 (Diff: 1)\n",
      "Semantic Similarities - Baseline: 0.3780, Steered: 0.4522 (Diff: 0.0743)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 9:\n",
      "Baseline: They're developing a new app for smartphones.\n",
      "Steered: They're developing a new drug for cancer treatment.\n",
      "Keyword Scores - Baseline: 0, Steered: 1 (Diff: 1)\n",
      "Semantic Similarities - Baseline: 0.3729, Steered: 0.4491 (Diff: 0.0762)\n",
      "The steered output is more aligned with the medical feature.\n",
      "\n",
      "Test Case 10:\n",
      "Baseline: He's passionate about environmental conservation.\n",
      "Steered: He's passionate about mental health awareness.\n",
      "Keyword Scores - Baseline: 0, Steered: 1 (Diff: 1)\n",
      "Semantic Similarities - Baseline: 0.3531, Steered: 0.4109 (Diff: 0.0578)\n",
      "The steered output is more aligned with the medical feature.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# List of medical keywords (expand this based on your feature and domain knowledge)\n",
    "medical_keywords = ['medicine', 'Medicine', 'medicines', 'medication', 'psychiatry', 'medicinal', 'Medic', 'medications', 'medical', 'physician', 'doctor', 'patient', 'hospital', 'diagnosis', 'treatment', 'nurse', 'surgery', 'clinic', 'therapy', 'health']\n",
    "\n",
    "def keyword_score(text, keywords):\n",
    "    return sum(keyword.lower() in text.lower() for keyword in keywords)\n",
    "\n",
    "def get_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Load pre-trained model for embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Reference text for similarity comparison\n",
    "reference_text = \" \".join(medical_keywords)\n",
    "reference_embedding = get_embedding(reference_text, model, tokenizer)\n",
    "\n",
    "def compare_texts(baseline_text, steered_text):\n",
    "    # Keyword matching\n",
    "    baseline_score = keyword_score(baseline_text, medical_keywords)\n",
    "    steered_score = keyword_score(steered_text, medical_keywords)\n",
    "\n",
    "    # Semantic similarity\n",
    "    baseline_embedding = get_embedding(baseline_text, model, tokenizer)\n",
    "    steered_embedding = get_embedding(steered_text, model, tokenizer)\n",
    "\n",
    "    baseline_similarity = cosine_similarity([baseline_embedding], [reference_embedding])[0][0]\n",
    "    steered_similarity = cosine_similarity([steered_embedding], [reference_embedding])[0][0]\n",
    "\n",
    "    return {\n",
    "        'baseline_score': baseline_score,\n",
    "        'steered_score': steered_score,\n",
    "        'baseline_similarity': baseline_similarity,\n",
    "        'steered_similarity': steered_similarity\n",
    "    }\n",
    "\n",
    "def evaluate_alignment(results):\n",
    "    keyword_diff = results['steered_score'] - results['baseline_score']\n",
    "    similarity_diff = results['steered_similarity'] - results['baseline_similarity']\n",
    "    \n",
    "    if keyword_diff > 0 or similarity_diff > 0.01:  # 0.01 is a small threshold to account for minor fluctuations\n",
    "        return \"The steered output is more aligned with the medical feature.\"\n",
    "    elif keyword_diff == 0 and abs(similarity_diff) <= 0.01:\n",
    "        return \"There is no significant difference in alignment between the outputs.\"\n",
    "    else:\n",
    "        return \"The baseline output is more aligned with the medical feature.\"\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (\"I think the most challenging career path is lawyer.\", \"I think the most challenging career path is doctor.\"),\n",
    "    (\"I think the most challenging career path is lawyer.\", \"I think the most challenging career path is nurse.\"),\n",
    "    (\"The project requires careful planning and execution.\", \"The surgery requires careful planning and execution.\"),\n",
    "    (\"She works long hours at the office.\", \"She works long hours at the hospital.\"),\n",
    "    (\"He's studying to become a teacher.\", \"He's studying to become a pharmacist.\"),\n",
    "    (\"The conference is about new technological advancements.\", \"The conference is about new medical advancements.\"),\n",
    "    (\"She's an expert in resolving conflicts.\", \"She's an expert in diagnosing rare diseases.\"),\n",
    "    (\"The book discusses modern management techniques.\", \"The book discusses modern treatment techniques.\"),\n",
    "    (\"They're developing a new app for smartphones.\", \"They're developing a new drug for cancer treatment.\"),\n",
    "    (\"He's passionate about environmental conservation.\", \"He's passionate about mental health awareness.\")\n",
    "]\n",
    "\n",
    "for i, (baseline, steered) in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    print(f\"Baseline: {baseline}\")\n",
    "    print(f\"Steered: {steered}\")\n",
    "    \n",
    "    results = compare_texts(baseline, steered)\n",
    "    \n",
    "    keyword_diff = results['steered_score'] - results['baseline_score']\n",
    "    similarity_diff = results['steered_similarity'] - results['baseline_similarity']\n",
    "    \n",
    "    print(f\"Keyword Scores - Baseline: {results['baseline_score']}, Steered: {results['steered_score']} (Diff: {keyword_diff})\")\n",
    "    print(f\"Semantic Similarities - Baseline: {results['baseline_similarity']:.4f}, Steered: {results['steered_similarity']:.4f} (Diff: {similarity_diff:.4f})\")\n",
    "    print(evaluate_alignment(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at Humberto/MedicalArticlesClassificationModel were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at Humberto/MedicalArticlesClassificationModel and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The patient presented with symptoms of fever and cough.\n",
      "Classification: Non-medical\n",
      "Confidence: 0.18\n",
      "\n",
      "Text: The stock market showed significant gains today.\n",
      "Classification: Medical\n",
      "Confidence: 0.18\n",
      "\n",
      "Text: A new study reveals potential treatments for Alzheimer's disease.\n",
      "Classification: Non-medical\n",
      "Confidence: 0.18\n",
      "\n",
      "Text: The movie received critical acclaim at the film festival.\n",
      "Classification: Medical\n",
      "Confidence: 0.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"Humberto/MedicalArticlesClassificationModel\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def classify_text(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Make a prediction\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get the predicted class (0 for non-medical, 1 for medical)\n",
    "    predicted_class = tf.argmax(outputs.logits, axis=1).numpy()[0]\n",
    "    \n",
    "    # Get the confidence score\n",
    "    confidence = tf.nn.softmax(outputs.logits, axis=1).numpy()[0][predicted_class]\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Test the model with some example texts\n",
    "test_texts = [\n",
    "    \"The patient presented with symptoms of fever and cough.\",\n",
    "    \"The stock market showed significant gains today.\",\n",
    "    \"A new study reveals potential treatments for Alzheimer's disease.\",\n",
    "    \"The movie received critical acclaim at the film festival.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    class_label, confidence = classify_text(text)\n",
    "    result = \"Medical\" if class_label == 1 else \"Non-medical\"\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Classification: {result}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The patient presented with symptoms of fever and cough.\n",
      "Classification: Certain infectious or parasitic diseases\n",
      "Confidence: 0.95\n",
      "\n",
      "Text: The stock market showed significant gains today.\n",
      "Classification: Mental behavioural or neurodevelopmental disorders\n",
      "Confidence: 0.19\n",
      "\n",
      "Text: A new study reveals potential treatments for Alzheimer's disease.\n",
      "Classification: diseases of the nervous system\n",
      "Confidence: 0.72\n",
      "\n",
      "Text: The movie received critical acclaim at the film festival.\n",
      "Classification: Neoplasms\n",
      "Confidence: 0.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"justpyschitry/Medical_Article_Classifier_by_ICD-11_Chapter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)  # Remove from_pt=True\n",
    "\n",
    "def classify_text(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Make a prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    # Get the confidence score\n",
    "    confidence = torch.softmax(outputs.logits, dim=1)[0][predicted_class].item()\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Test the model with some example texts\n",
    "test_texts = [\n",
    "    \"The patient presented with symptoms of fever and cough.\",\n",
    "    \"The stock market showed significant gains today.\",\n",
    "    \"A new study reveals potential treatments for Alzheimer's disease.\",\n",
    "    \"The movie received critical acclaim at the film festival.\"\n",
    "]\n",
    "\n",
    "# Get the label mappings\n",
    "id2label = model.config.id2label\n",
    "\n",
    "for text in test_texts:\n",
    "    class_label, confidence = classify_text(text)\n",
    "    result = id2label[class_label]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Classification: {result}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
