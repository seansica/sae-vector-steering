{
    "model_name": "gpt2-small",
    "model_class_name": "HookedTransformer",
    "hook_name": "blocks.0.hook_mlp_out",
    "hook_eval": "NOT_IN_USE",
    "hook_layer": 0,
    "hook_head_index": null,
    "dataset_path": "monology/pile-uncopyrighted",
    "dataset_trust_remote_code": true,
    "streaming": true,
    "is_dataset_tokenized": false,
    "context_size": 128,
    "use_cached_activations": false,
    "cached_activations_path": null,
    "architecture": "standard",
    "d_in": 768,
    "d_sae": 1536,
    "b_dec_init_method": "geometric_median",
    "expansion_factor": 2,
    "activation_fn": "relu",
    "activation_fn_kwargs": {},
    "normalize_sae_decoder": true,
    "noise_scale": 0.0,
    "from_pretrained_path": null,
    "apply_b_dec_to_input": true,
    "decoder_orthogonal_init": false,
    "decoder_heuristic_init": false,
    "init_encoder_as_decoder_transpose": false,
    "n_batches_in_buffer": 16,
    "training_tokens": 1000000,
    "finetuning_tokens": 0,
    "store_batch_size_prompts": 8,
    "train_batch_size_tokens": 1024,
    "normalize_activations": "none",
    "device": "mps",
    "act_store_device": "mps",
    "seed": 42,
    "dtype": "float32",
    "prepend_bos": true,
    "autocast": false,
    "autocast_lm": false,
    "compile_llm": false,
    "llm_compilation_mode": null,
    "compile_sae": false,
    "sae_compilation_mode": null,
    "adam_beta1": 0,
    "adam_beta2": 0.999,
    "mse_loss_normalization": null,
    "l1_coefficient": 1.0,
    "lp_norm": 1,
    "scale_sparsity_penalty_by_decoder_norm": false,
    "l1_warm_up_steps": 0,
    "lr": 0.0001,
    "lr_scheduler_name": "constant",
    "lr_warm_up_steps": 0,
    "lr_end": 1e-05,
    "lr_decay_steps": 0,
    "n_restart_cycles": 1,
    "finetuning_method": null,
    "use_ghost_grads": false,
    "feature_sampling_window": 2000,
    "dead_feature_window": 1000,
    "dead_feature_threshold": 1e-08,
    "n_eval_batches": 10,
    "eval_batch_size_prompts": null,
    "log_to_wandb": false,
    "log_activations_store_to_wandb": false,
    "log_optimizer_state_to_wandb": false,
    "wandb_project": "mats_sae_training_language_model",
    "wandb_id": null,
    "run_name": "1536-L1-1.0-LR-0.0001-Tokens-1.000e+06",
    "wandb_entity": null,
    "wandb_log_frequency": 10,
    "eval_every_n_wandb_logs": 100,
    "resume": false,
    "n_checkpoints": 0,
    "checkpoint_path": "checkpoints/cnz8cziy",
    "verbose": true,
    "model_kwargs": {},
    "model_from_pretrained_kwargs": {},
    "sae_lens_version": "3.12.0",
    "sae_lens_training_version": "3.12.0",
    "tokens_per_buffer": 2097152
}